<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0" name="viewport">
    <title>Using Sentiment Analysis to Design a Drug Recommendation Application</title>
    <meta content="" name="description">
    <meta content="" name="keywords">
    <!-- Favicons -->
    <link href="../../assets/img/web-icon.png" rel="icon">
    <link href="../../assets/img/apple-touch-icon.png" rel="apple-touch-icon">
    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Roboto:300,300i,400,400i,500,500i,700,700i&display=swap" rel="stylesheet">
    <!-- Vendor CSS Files -->
    <link href="../../assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="../../assets/vendor/animate.css/animate.min.css" rel="stylesheet">
    <link href="../../assets/vendor/icofont/icofont.min.css" rel="stylesheet">
    <link href="../../assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
    <link href="../../assets/vendor/venobox/venobox.css" rel="stylesheet">
    <link href="../../assets/vendor/owl.carousel/assets/owl.carousel.min.css" rel="stylesheet">
    <link href="../../assets/vendor/aos/aos.css" rel="stylesheet">
    <!-- Template Main CSS File -->
    <link href="../../assets/css/style.css" rel="stylesheet">
    <link href="../../assets/css/prism.css" rel="stylesheet">
  </head>
  <body>
    <!-- ======= Header ======= -->
    <header id="header" class="fixed-top ">
      <div class="container">
        <div class="logo float-left">
                <h1 class="text-light"><a href="../../index.html"><span>Alimr.dev</a></h1>
        </div>
        <nav class="nav-menu float-right d-none d-lg-block">
          <ul>
            <li><a href="../../index.html">Home</a></li>
            <li class="active"><a href="../../projects.html">Projects</a></li>
            <li class="drop-down"><a href="../../tutorials.html">Tutorials</a>
            <ul>
              <li><a href="../../tutorials.html#Pandas">Pandas</a></li>
              <li class="drop-down"><a href="../../tutorials.html#Machine-Learning">Machine Learning</a>
              <ul>
                <li><a href="linear_regression.html">Linear Regression</a></li>
                <li><a href="linear_regression.html">Support Vector Machines</a></li>
                <li><a href="linear_regression.html">Naive Bayes</a></li>
                <li><a href="linear_regression.html">Decision Trees</a></li>
                <li><a href="linear_regression.html">Ensemble Methods</a></li>
              </ul>
            </li>
            <li><a href="../../tutorials.html#Linear-Algebra">Linear Algebra</a></li>
            <li><a href="../../tutorials.html#Visualization">Visualization</a></li>
            <li><a href="../../tutorials.html#Jupyter-Notebook">Jupyter Notebook</a></li>
            <li><a href="../../tutorials.html#Git">Git</a></li>
            <li><a href="../../tutorials.html#Bash">Bash</a></li>
            <li><a href="../../tutorials.html#Deep-Learning">Deep Learning</a></li>
            <li><a href="../../tutorials.html#Conda">Conda</a></li>
            <li><a href="../../tutorials.html#Numerical-Methods">Numerical Methods</a></li>
            <li><a href="../../tutorials.html#Big-Data">Big Data</a></li>
            <li><a href="../../tutorials.html#Classification">Classification</a></li>
            <li><a href="../../tutorials.html#Pattern-Recognition">Pattern Recognition</a></li>
            <li><a href="../../tutorials.html#SQL">SQL</a></li>
          </ul>
        </li>
        <li><a href="../../about.html">About Me</a></li>
        <li><a href="../../contact.html">Contact</a></li>
      </ul>
      </nav><!-- .nav-menu -->
    </div>
    </header><!-- End Header -->
    <main id="main">
      <!-- ======= About Us Section ======= -->
      <section class="breadcrumbs">
        <div class="container">
          <div class="d-flex justify-content-between align-items-center">
            <h2>Projects</h2>
            <ol>
              <li><a href="../../projects2.html">Projects</a></li>
              <li>Using Sentiment Analysis to Design a Drug Recommendation Application</li>
            </ol>
          </div>
        </div>
      </section>
      <!-- End Header -->
      <section class="tutorials" data-aos="fade-up" data-aos-easing="ease-in-out" data-aos-duration="1000">
        <div class="container">
          <div class="row">
            <div class="col-12">
                <h2  id="title"><font color='green'>Opti</font><font color='orange'>Med</font> - What <font color='orange'>Medicine</font> <font color='green'>Best</font> Suits Your Need?</h2>
                <div style="text-align:center">
                  <span><a id="fig1" style="font-size: 1.5em;"></a></span>
                </div>
                <p class="text-align: center;">
                  <img src="project_cover.jpeg" style="width: 80%; display: block; margin: 10px auto 20px;"/>
                </p>
                
                <h3>Motivation and summary of the project</h3>
                <p>
                  I had this idea about building an application that can diagnose your causes of discomfort and pain and suggest you the drugs that fit that description! I spent some time and looked at the different data sources that I knew such as <a href="https://www.reddit.com/r/dataisbeautiful"><strong>Data is beautiful</strong></a>, <a href="https://data.world/"><strong>data.world</strong></a>, <a href="https://tinyletter.com/data-is-plural/letters/data-is-plural-2020-06-17-edition"><strong>Data is plural</strong></a>, <a href="https://www.kaggle.com/datasets"><strong>kaggle</strong></a>, <a href="https://archive.ics.uci.edu/ml/datasets.php"><strong>UCI datasets</strong></a> and so on and found a <a href="https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29"><strong>Drug Review Dataset (Drugs.com)</strong></a> about cutomer reviews of 3671 unique drugs.
                </p>
                <p>
                  I thought there are probably many people like me neither know nor look for the drug that best fits their symptoms and just go with that one drug that they always relied on when they had a headache ... So I thought about different ways that this data set can be used to 
                </p>
                  <ol>
                    <li>Drug recommender: find the best hit from the data set using:</li>
                    <ul>
                      <li>the patient symptoms</li>
                      <li>the patient location (living close to CVS, Walgreens etc.)</li>
                      <li>budget</li>
                      <li>potential allergies or drug intolerance</li>
                      <li>other drugs being taken currently (if any) that can cause drug interactions</li>
                      <li>urgency of the situation (might influence the importance of the location)</li>
                    </ul>
                    <li>Review-score predictor: predict the rating of a review using the review test</li>
                    <li>Review classifier: predict whether the review has a <strong>positive</strong>, <strong>neutral</strong>, or <strong>negative</strong>.</li>
                  </ol>
                <p>
                  For the drug-recommendation idea, I thought about some other resources which can be used to improve the predictive and analytic power of the application. For instance, a lot of us know that the brand drugs addressing a certain condition could be an order of magnitude more expensive than the generic drugs to the point that your insurance company might refuse to pay for the brand drug if prescribed by your primary care physician. So I thought about finding/creating a database that contains all the medical conditions with all different drugs addressing each condition. Here is the list of other potential development ideas:
                  <ul>
                    <li>Use other resources such as <strong><a href="https://www.drugbank.ca/">Drug Bank</a></strong> to make the model more robust by considering potential <strong><em>drug interactions, side effects</em></strong> etc.</li>
                    <li>Use other APIs such as <strong><a href="https://www.goodrx.com/">GoodRx</a></strong> to build a <strong>real-time model</strong> that considers other user-defined factors such as <strong><em>location, price range, and ease of transportation, weather condition, delivery options</em></strong> etc. to make a more calculated decision</li>
                    <li>Expand the usefulness of the app to <strong><em>medical professionals</em></strong> so that they can offer <strong><em>patients-customized solutions</em></strong> </strong></li>
                  </ul>
                </p>
                <p>
                  In the first part of the project, I will try different NLP models to find the model that can best predict the review score using the review text only. Here are some of the questions that are aimed to answer by doing this project:
                  <ul>
                    <li>Can we build a model to predict the review rating from the review text?</li>
                    <li>Can features that are seemingly irrelevant to the review content, e.g., the review date, the medical condition etc. be incorporated towards making the sentiment analysis model more accurate?</li>
                    <li>What vectorization methods are more effective in serving the purpose of this project?</li>
                    <li>If the model does a good job in identifying the drug names using patient condition, can we use that to design a drug recommendation app?</li>
                  </ul>
                </p>
                <h3>Table of Contents</h3>
                <p>
                  <ul>
                    <li><a href="#data-exploration">Data Exploration</a></li>
                    <ul>
                    <li><a href="#loading-libraries">Loading the required libraries</a></li>
                    <li><a href="#data_set">Data Set Information</a></li>
                    <li><a href="#data_usage">Data Usage Policy</a></li>
                    <li><a href="#attribute_information">Attribute Information</a></li>
                    <li><a href="#basic_statistics">Basic Statistics of the Data</a></li>
                    </ul>
                    <li><a href="#data_exploration">Data Preprocessing and Imputation</a></li>
                    <li><a href="#EDA">Exploratory Data Analysis</a></li>
                    <ul>
                    <li><a href="#user_rating_hist">User rating histogram for train and test data</a></li>
                    <li><a href="#review_count_years">Variation of review count over the years</a></li>
                    <li><a href="#weekday_ratings">Mean weekday, monthly, and annual ratings</a></li>
                    <li><a href="#common_conditions">Most common medical conditions</a></li>
                    <li><a href="#drugs_many_conditions">Drugs that are prescribed for many conditions</a></li>
                    <li><a href="#conditions_many_drugs">Conditions that are treated using multiple different drugs</a></li>
                    <li><a href="#usefulcount_rating">Variation of <code>usefulCount</code> with <code>rating</code></a></li>
                    </ul>
                    <li><a href="#sentiment_analysis">Sentiment Analysis</a></li>
                    <ul>
                    <li><a href="#data_preparation_for">Data preparation for sentiment analysis</a></li>
                    <li><a href="#stopwords">Stopwords</a></li>
                    <li><a href="#cleaning_tokenization">Cleaning, tokenization, and stemming</a></li>
                    <li><a href="#wordcloud">WordCloud</a></li>
                    <li><a href="#language_models">Language Models</a></li>
                    <li><a href="#bag_of_words">Bag of words</a></li>
                    <li><a href="#n-grams">n-grams</a></li>
                    <ul>
                    <li><a href="#visualizing_most_frequent">Visualizing most frequent <em>n-grams</em></h5></li>
                    </ul>
                    <li><a href="#feature_engineering">Feature Engineering</a></li>
                    <li><a href="#correlation_plot">Correlation Plot</a></li>
                  </ul>
                </p>
                <h3 id="data-exploration">Data Exploration</h3>
                <p>We start off by importing some python libraries that are required for this project. Our first objective is to load and explore the data to get familiar with the features, data types, data distributions etc.</p>
                <h3 id="loading-libraries">Loading the required libraries</h3>
                <pre class="prettyprint lang-language"><code class="language-python">import os
import re
import sys
import nltk
import warnings
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import chart_studio.plotly as py 
import plotly.graph_objs as go #importing graphical objects
from textblob import TextBlob
from matplotlib import cm as cm
from IPython.display import Image
from matplotlib import rc, rcParams
from IPython.core.display import HTML
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
from viz import *
from toggle_cell import toggle_code as hide_cell
from matplotlib.colors import Normalize
from scipy import stats
from scipy.stats import norm
warnings.filterwarnings('ignore')
rcParams['font.family'] = 'serif'
rc('font',**{'family':'serif','serif':['Helvetica']})
rc('text', usetex=False)
# rc('text.latex', preamble=r'\usepackage{underscore}')
np.set_printoptions(precision=3)
pd.set_option('display.float_format', lambda x: '%.3f' % x)
sns.set_style('white')
sns.set(rc={"figure.dpi":100})</code></pre>
                <p>The data was obtained from <a href="https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29#">UCI Drug Review Dataset (Drugs.com)</a>. The following is the data description provided by the reference:</p>
                <h3 id="data_set">Data Set Information</h3>
                <p>
                  The dataset provides patient reviews on specific drugs along with related conditions and a 10 star patient rating reflecting overall patient satisfaction. The data was obtained by crawling online pharmaceutical review sites. The intention was to study
                </p>
                <ol>
                  <li>
                    Sentiment analysis of drug experience over multiple facets, i.e. sentiments learned on specific aspects such as effectiveness and side effects,
                  </li>
                  <li>
                    the transferability of models among domains, i.e. conditions, and
                  </li>
                  <li>
                    the transferability of models among different data sources (see <a href='https://archive.ics.uci.edu/ml/machine-learning-databases/00461/'>UCI Drug Review Dataset (Druglib.com)</a>).
                  </li>
                </ol>
                <p>
                  The data is split into a train (75%) a test (25%) partition (see publication) and stored in two .tsv (tab-separated-values) files, respectively.
                </p>
                <h4 id="data_usage">Data Usage Policy</h4>
                <p>When using this dataset, you agree that you</p>
                <ol>
                  <li>only use the data for research purposes</li>
                  <li>don't use the data for any commerical purposes</li>
                  <li>don't distribute the data to anyone else</li>
                </ol>
                <h4 id="attribute_information">Attribute Information</h4>
                <ol style="list-style-type: decimal">
                  <li><strong>uniqueID</strong>: the ID unique to each patient that has written the review</li>
                  <li><strong>drugName</strong> (categorical): name of the drug</li>
                  <li><strong>condition</strong> (categorical): condition that the drug was used to address</li>
                  <li><strong>review</strong> (text): patient review</li>
                  <li><strong>rating</strong> (numerical 0-10)</li>
                  <li><strong>date</strong> (date): the date review was posted</li>
                  <li><strong>usefulCount</strong> (numerical): number of users that found the review useful</li>
                </ol>
                <pre class="prettyprint lang-language"><code class="language-python">df_train = pd.read_csv('data/drugsComTrain_raw.csv', parse_dates=['date'])
df_test = pd.read_csv('data/drugsComTest_raw.csv', parse_dates=['date'])
df_train.head()</code></pre>
                <table class="table table-striped">
                  <thead>
                    <tr style="text-align: left;">
                      <th></th>
                      <th>uniqueID</th>
                      <th>drugName</th>
                      <th>condition</th>
                      <th>review</th>
                      <th>rating</th>
                      <th>date</th>
                      <th>usefulCount</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <th scope="row">0</th>
                      <td>206461</td>
                      <td>Valsartan</td>
                      <td>Left Ventricular Dysfunction</td>
                      <td>"It has no side effect, I take it in combinati...</td>
                      <td>9</td>
                      <td>2012-05-20</td>
                      <td>27</td>
                    </tr>
                    <tr>
                      <th scope="row">1</th>
                      <td>95260</td>
                      <td>Guanfacine</td>
                      <td>ADHD</td>
                      <td>"My son is halfway through his fourth week of ...</td>
                      <td>8</td>
                      <td>2010-04-27</td>
                      <td>192</td>
                    </tr>
                    <tr>
                      <th scope="row">2</th>
                      <td>92703</td>
                      <td>Lybrel</td>
                      <td>Birth Control</td>
                      <td>"I used to take another oral contraceptive, wh...</td>
                      <td>5</td>
                      <td>2009-12-14</td>
                      <td>17</td>
                    </tr>
                    <tr>
                      <th scope="row">3</th>
                      <td>138000</td>
                      <td>Ortho Evra</td>
                      <td>Birth Control</td>
                      <td>"This is my first time using any form of birth...</td>
                      <td>8</td>
                      <td>2015-11-03</td>
                      <td>10</td>
                    </tr>
                    <tr>
                      <th scope="row">4</th>
                      <td>35696</td>
                      <td>Buprenorphine / naloxone</td>
                      <td>Opiate Dependence</td>
                      <td>"Suboxone has completely turned my life around...</td>
                      <td>9</td>
                      <td>2016-11-27</td>
                      <td>37</td>
                    </tr>
                  </tbody>
                </table>
                <h4 id="basic_statistics">Basic Statistics of the Data</h4>
                <pre class="prettyprint lang-language"><code class="language-python">pd.concat([df_train.describe(),df_test.describe()], axis=1)</code></pre>
                <table class="table table-striped">
                  <thead>
                    <tr style="text-align: left;">
                      <th></th>
                      <th>uniqueID</th>
                      <th>rating</th>
                      <th>usefulCount</th>
                      <th>uniqueID</th>
                      <th>rating</th>
                      <th>usefulCount</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <th>count</th>
                      <td>161297.000</td>
                      <td>161297.000</td>
                      <td>161297.000</td>
                      <td>53766.000</td>
                      <td>53766.000</td>
                      <td>53766.000</td>
                    </tr>
                    <tr>
                      <th>mean</th>
                      <td>115923.585</td>
                      <td>6.994</td>
                      <td>28.005</td>
                      <td>116386.701</td>
                      <td>6.977</td>
                      <td>27.990</td>
                    </tr>
                    <tr>
                      <th>std</th>
                      <td>67004.445</td>
                      <td>3.272</td>
                      <td>36.404</td>
                      <td>67017.740</td>
                      <td>3.285</td>
                      <td>36.173</td>
                    </tr>
                    <tr>
                      <th>min</th>
                      <td>2.000</td>
                      <td>1.000</td>
                      <td>0.000</td>
                      <td>0.000</td>
                      <td>1.000</td>
                      <td>0.000</td>
                    </tr>
                    <tr>
                      <th scope="row">25%</th>
                      <td>58063.000</td>
                      <td>5.000</td>
                      <td>6.000</td>
                      <td>58272.500</td>
                      <td>4.000</td>
                      <td>6.000</td>
                    </tr>
                    <tr>
                      <th scope="row">50%</th>
                      <td>115744.000</td>
                      <td>8.000</td>
                      <td>16.000</td>
                      <td>116248.500</td>
                      <td>8.000</td>
                      <td>16.000</td>
                    </tr>
                    <tr>
                      <th scope="row">75%</th>
                      <td>173776.000</td>
                      <td>10.000</td>
                      <td>36.000</td>
                      <td>174586.750</td>
                      <td>10.000</td>
                      <td>36.000</td>
                    </tr>
                    <tr>
                      <th>max</th>
                      <td>232291.000</td>
                      <td>10.000</td>
                      <td>1291.000</td>
                      <td>232284.000</td>
                      <td>10.000</td>
                      <td>949.000</td>
                    </tr>
                  </tbody>
                </table>
                <pre class="prettyprint lang-language"><code class="language-python">print(f'train and test shapes are {df_train.shape} and {df_test.shape}, respectively.')
</code></pre>
                <pre><code>train and test shapes are (161297, 7) and (53766, 7), respectively.</code></pre>
                <h3 id="data_exploration">Data Preprocessing and Imputation</h3>
                <p>
                  We can start by looking at the reviews. 
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">df_train['review'].tail()</code></pre>
<pre>161292    "I wrote my first report in Mid-October of 201...
161293    "I was given this in IV before surgey. I immed...
161294    "Limited improvement after 4 months, developed...
161295    "I&#38;&#35;039&#59;ve been on thyroid medication 49 years...
161296    "I&#38;&#35;039&#59;ve had chronic constipation all my adu...
Name: review, dtype: object</pre>
                <p>
                  Patient reviews include some unwanted html characters which can be removed using <code class='module'>'html.parser'</code> module of <code class="library"><a href="https://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a></code>.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">from bs4 import BeautifulSoup

def remove_html(raw_review):
# 1. Remove HTML characters
    return BeautifulSoup(raw_review, 'html.parser').get_text()
df_test['review'].apply(remove_html)
df_train['review'].apply(remove_html).tail()</code></pre>
                <pre><code>161292    "I wrote my first report in Mid-October of 201...
161293    "I was given this in IV before surgey. I immed...
161294    "Limited improvement after 4 months, developed...
161295    "I've been on thyroid medication 49 years, I s...
161296    "I've had chronic constipation all my adult li...
Name: review, Length: 161297, dtype: object</code></pre>
                <p>
                  The same issue exists for the <code>condition</code> column so we repeat the cleaning for this column as well. However, we first need to change the data-type of this column from <code>'O'</code> (object) to <code>string</code>.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">df_test['condition']=df_test['condition'].astype(str).apply(remove_html)
df_train['condition']=df_train['condition'].astype(str).apply(remove_html)</code></pre>
                <p>
                  We will examine the column to identify the missing values
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">for col in df_train.columns:
    if df_train[col].isnull().values.any():
        print('train data has {0:d} missing values in column "{1:s}" ({2:.3f}%)'
              .format(len(df_train[df_train[col].isna()]),
                      col, 
                      len(df_train[df_train[col].isna()]) / len(df_train)))
    if df_test[col].isnull().values.any():
        print('test data has {0:d} missing values in column "{1:s}" ({2:.3f}%)'
              .format(len(df_test[df_test[col].isna()]),
                      col, 
                      len(df_test[df_test[col].isna()]) / len(df_test)))</code></pre>
                <pre><code>train data has 899 missing values in column "condition" (0.006%)
test data has 295 missing values in column "condition" (0.005%)</code></pre>
                <p>
                  We drop the missing elements as the number of missing values are not significant relative to the entire population. 
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">df_train = df_train.dropna(axis=0)
df_test = df_test.dropna(axis=0)</code></pre>
                <p>
                  Next, we'll make some <em>observations</em> regarding the relatonships between the features using Exploratory Data Analysis. 
                </p>
                <h3 id="EDA">Exploratory Data Analysis</h3>
                <p>
                  We can take a look at the unique values for <code>uniqueID</code>, <code>drugName</code>, and <code>condition</code> to:
                <ul>
                  <li>See if there are <strong>multiple reviews</strong> from a single user,</li>
                  <li>Get a sense of the number of <strong>unique drugs</strong> in the data set,</li>
                  <li>Find the drugs that are most commonly used,</li>
                  <li>...</li>
                </ul>
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">df_all = df_train.append(df_test, ignore_index=True)
for col in ['uniqueID', 'drugName', 'condition']:
    print('{0:d} unique values for {1:s} in train data of length {2:d}' \
        .format(len(df_train[col].unique().tolist()), col, len(df_train)))
    print('{0:d} unique values for {1:s} in test data of length {2:d}' \
        .format(len(df_test[col].unique().tolist()), col, len(df_test)))
    print('{0:d} unique values for {1:s} in the entire data of length {2:d}' \
        .format(len(df_all[col].unique().tolist()), col, len(df_all)))</code></pre>
                <pre><code>161297 unique values for uniqueID in train data of length 161297
53766 unique values for uniqueID in test data of length 53766
215063 unique values for uniqueID in the entire data of length 215063
3436 unique values for drugName in train data of length 161297
2637 unique values for drugName in test data of length 53766
3671 unique values for drugName in the entire data of length 215063
885 unique values for condition in train data of length 161297
709 unique values for condition in test data of length 53766
917 unique values for condition in the entire data of length 215063</code></pre>
                <p>
                  Note that the total number of <code>uniqueID</code>s is equal to the sum of <code>uniqueID</code>s in the train and test data, meaning that each patient has written one review. We can now make some <em>observations</em> regarding some of the features of the dataset.
                </p>
                <h4 id="user_rating_hist">User rating histogram for train and test data</h4>
                <pre class="prettyprint lang-language"><code class="language-python">sns.set(style="white", palette="muted")
f, axes = plt.subplots(1, 2, figsize=(14, 7), sharex=False, sharey=False)
sns.despine(left=False)
colors = ['blue', 'orange']
data_labels = ['train', 'test']
plots, handles = [], []
for i, data in enumerate([df_train, df_test]):
    plots.append(sns.distplot(data['rating'],
                              kde=False, 
                              color=colors[i], 
                              ax=axes[i], 
                              label=data_labels[i])
                )
    plots[i].set_xticks(np.arange(1,11))
    h, l = plots[i].get_legend_handles_labels()
    handles.append(h[0])
plt.legend(labels=data_labels, 
           handles=handles, 
           bbox_to_anchor=(1,1,0,0), 
           loc='center left', 
           fontsize=12)
plt.suptitle('Patient review-rating distributions for train and test data', fontsize=20)
plt.tight_layout()
plt.show()</code></pre>
                <div style="text-align: center;">
                  <a id="fig2" style="font-size: 1.5em;">Figure 2</a>
                </div>
                <p class="text-align: center;">
                  <img src="output_23_0.png" style="width: 100%; display: block; margin: 10px auto 20px;"/>
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">sns.set(style="white", palette="muted")
f, ax = plt.subplots(1, 1, figsize=(7, 7))
sns.despine(left=False)
df_all['year'] = df_all['date'].dt.year
df_all['month'] = df_all['date'].dt.month
df_all['weekday'] = df_all['date'].dt.weekday
years=sorted(df_all['year'].unique())
g = sns.distplot(df_all['year'],bins=len(years),
                 kde=False, 
                 ax=ax)
# fix the ticks and labels
for i,rect in enumerate(g.patches):
    rect.set_width(1)
    rect.set_x(years[i]-0.5)
ax.set_xticks(list(np.asarray(years)))
plt.suptitle('Number of reviews per year', fontsize=20)
plt.tight_layout()
plt.show()</code></pre>
                <div style="text-align:center">
                <a id="fig3" style="font-size: 1.5em;">Figure 3</a>
                </div>
                <p class="text-align: center;">
                  <img src="output_24_0.png" style="width: 60%; display: block; margin: 10px auto 20px;"/>
                </p>
                
                <h4 id="review_count_years">Variation of review count over the years</h4>
                <pre class="prettyprint lang-language"><code class="language-python">sns.set(style="white", palette="muted")
f, ax = plt.subplots(1, 1, figsize=(7, 7))
sns.despine(left=False)
month_names = [month_name[x] for x in np.arange(1,13)];
df_all['month'] = df_all['date'].dt.month
months=sorted(df_all['month'].unique())
g = sns.distplot(df_all['month'],bins=len(months),
                 kde=False, 
                 ax=ax)
# fix the ticks and ticklabels
for i,rect in enumerate(g.patches):
    rect.set_width(1)
    rect.set_x(months[i]-0.5)
g.set_xticks(months)
g.set_xticklabels(month_names, rotation=90)
plt.suptitle('Number of reviews for each month', fontsize=20)
plt.tight_layout()
plt.show()</code></pre>
                <div style="text-align:center">
                <a id="fig4" style="font-size: 1.5em;">Figure 4</a>
                </div>
                <p class="text-align: center;">
                  <img src="output_25_0.png" style="width: 60%; display: block; margin: 10px auto 20px;"/>
                </p>
                <h4 id="weekday_ratings">Mean weekday, monthly, and annual ratings</h4>
                <pre class="prettyprint lang-language"><code class="language-python">weekdays = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']
f, ax = plt.subplots(3, 1, figsize=(14, 14), sharex=False, dpi=200)
g_y = sns.boxplot(x='year', y='rating',data=df_all, ax=ax[0], palette="Paired", showmeans=True)
g_m = sns.boxplot(x='month', y='rating',data=df_all, ax=ax[1], palette="Paired", showmeans=True)
g_d = sns.boxplot(x='weekday', y='rating',data=df_all, ax=ax[2], palette="Paired", showmeans=True)
g_d.set_xticklabels(weekdays);
g_m.set_xticklabels(month_names);
plt.suptitle('Average user rating for each weekday, month, and year', fontsize=22, y=0.92);</code></pre>
                <div style="text-align:center">
                  <a id="fig5" style="font-size: 1.5em;">Figure 5</a>
                </div>
                <p class="text-align: center;">
                  <img src="output_26_0.png" style="width: 100%; display: block; margin: 10px auto 20px;"/>
                </p>
                <p>Hmmm... Drugs getting worse or user becoming more critical?</p>
                <h4 id="common_conditions">Most common medical conditions</h4>
                <pre class="prettyprint lang-language"><code class="language-python">fig, ax = plt.subplots(1, 1, figsize=(16, 6), dpi=200)
n_conditions = 20
g = sns.countplot(x='condition', 
                  data=df_all, 
                  order=df_all.condition \
                              .value_counts() \
                              .iloc[:n_conditions] \
                              .index, 
                  ax=ax)
g.set_xlabel(g.get_xlabel(), fontsize=22)
g.set_ylabel(g.get_ylabel(), fontsize=22, labelpad=10)
ylabs = g.get_yticklabels()
plt.setp(ax.get_xticklabels(), rotation=45, ha='right', fontsize=16)
plt.setp(ax.get_yticklabels(), fontsize=16)
g.set_title(f'Top {n_conditions} frequent medical conditions',y=1.05, fontsize=28)
sns.despine(left=False)</pre></code>
                <div style="text-align:center">
                <a id="fig5_1" style="font-size: 1.5em;">Figure 6</a>
                </div>
                <p class="text-align: center;">
                  <img src="output_new_1.png" style="width: 100%; display: block; margin: 10px auto 20px;"/>
                </p>
                <h4 id="drugs_many_conditions">Drugs that are prescribed for many conditions</h4>
                <p>
                  Another interesting observation is to look at the numebr of drugs that are used to address mutiple different medical conditions and see how the user ratings change for each condition. In other words, if a drug is known to be good for addressing condition 'A' does that mean it will do a good job in adressing condition 'B'?
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">n_drugs = 20
drugs_w_most_cond = df_all.groupby(['drugName'])['condition'] \
      .nunique() \
      .sort_values(ascending=False)[:n_drugs]
print(drugs_w_most_cond)</code></pre>
                <pre>drugName
Prednisone        39
Gabapentin        31
Ciprofloxacin     25
Doxycycline       25
Amitriptyline     24
Neurontin         23
Metronidazole     23
Venlafaxine       23
Lyrica            22
Dexamethasone     22
Zoloft            21
Cymbalta          20
Triamcinolone     20
Azithromycin      20
Clarithromycin    19
Seroquel          19
Effexor XR        19
Cipro             18
Sertraline        18
Naproxen          18
Name: condition, dtype: int64</pre>
                <pre class="prettyprint lang-language"><code class="language-python">fig, ax = plt.subplots(1, 1, figsize=(16, 6), dpi=200)
drug_arr = []
for i, (drug, count) in enumerate(drugs_w_most_cond.items()):
    drug_arr += count*[drug]
    tmp_df = pd.DataFrame(drug_arr, columns=['drug'])
g = sns.countplot(x='drug', data=tmp_df, ax=ax)
g.set_xlabel(g.get_xlabel(), fontsize=22)
g.set_ylabel(g.get_ylabel(), fontsize=22, labelpad=10)
ylabs = g.get_yticklabels()
plt.setp(ax.get_xticklabels(), rotation=45, ha='right', fontsize=16)
plt.setp(ax.get_yticklabels(), fontsize=16)
g.set_title('Drugs addressing the most unmber of unique medical conditions',y=1.05, fontsize=28)
sns.despine(left=False)</pre></code>
                <div style="text-align:center">
                <a id="fig6" style="font-size: 1.5em;">Figure 7</a>
                </div>
                <p class="text-align: center;">
                  <img src="output_27_0.png" style="width: 100%; display: block; margin: 10px auto 20px;"/>
                </p>
                  <h4 id="conditions_many_drugs">Conditions that are treated using multiple different drugs</h4>
                <p>
                  Similar to previous analysis, we can take a look at the conditions that are treated using variety of drugs.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">n_conditions = 20
conditions_w_most_drugs = df_all.groupby(['condition'])['drugName'] \
                          .nunique() \
                          .sort_values(ascending=False)[:n_conditions]
print(conditions_w_most_drugs)</code></pre>
                <pre>condition
Not Listed / Othe                      253
Pain                                   219
Birth Control                          181
High Blood Pressure                    146
Acne                                   127
Depression                             115
Rheumatoid Arthritis                   107
Diabetes, Type 2                        97
Allergic Rhinitis                       95
Insomnia                                85
Osteoarthritis                          84
Bipolar Disorde                         82
Anxiety                                 81
Abnormal Uterine Bleeding               77
Endometriosis                           64
3 users found this comment helpful.     62
Psoriasis                               61
Migraine                                60
ADHD                                    58
4 users found this comment helpful.     57
Name: drugName, dtype: int64
                </pre>
                <p>
                  Note that there are some conditions that we need to remove, i.e. <code>Not Listed / Othe </code>, <code>3 users found this comment helpful</code> , and <code>4 users found this comment helpful</code>. We can define a pattern using <strong>regular expressions</strong> to find the problematic rows as follows.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">df_all[df_all.condition.str.contains('(^nan$|Not Listed|found this comment helpful)')].head()</code></pre>
                <table class="table table-striped">
                  <thead>
                    <tr style="text-align: left;">
                      <th></th>
                      <th>uniqueID</th>
                      <th>drugName</th>
                      <th>condition</th>
                      <th>review</th>
                      <th>rating</th>
                      <th>date</th>
                      <th>usefulCount</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <th>104</th>
                      <td>220696</td>
                      <td>Loestrin 24 Fe</td>
                      <td>2 users found this comment helpful.</td>
                      <td>"I'm 16 and  I have been on Loestrin 24 f...</td>
                      <td>3</td>
                      <td>2010-11-03</td>
                      <td>2</td>
                    </tr>
                    <tr>
                      <th>194</th>
                      <td>67383</td>
                      <td>Provera</td>
                      <td>4 users found this comment helpful.</td>
                      <td>"I'm 24 years old and have always had a p...</td>
                      <td>1</td>
                      <td>2016-03-27</td>
                      <td>4</td>
                    </tr>
                    <tr>
                      <th>241</th>
                      <td>81588</td>
                      <td>Yaz</td>
                      <td>3 users found this comment helpful.</td>
                      <td>"I took Yaz for a little over 2 years.  From a...</td>
                      <td>3</td>
                      <td>2010-06-01</td>
                      <td>3</td>
                    </tr>
                    <tr>
                      <th>262</th>
                      <td>132965</td>
                      <td>Loestrin 24 Fe</td>
                      <td>4 users found this comment helpful.</td>
                      <td>"Took this pill for 1.) Acne and 2.) Birth Con...</td>
                      <td>2</td>
                      <td>2014-06-24</td>
                      <td>4</td>
                    </tr>
                    <tr>
                      <th>389</th>
                      <td>91050</td>
                      <td>Norco</td>
                      <td>11 users found this comment helpful.</td>
                      <td>"I have suffered with low back pain - 2 surger...</td>
                      <td>9</td>
                      <td>2009-03-15</td>
                      <td>11</td>
                    </tr>
                  </tbody>
                </table>
                <p>
                  We drop the rows corresponding to the mis-parsed conditions and then plot the data.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">bad_indices = df_all[df_all.condition.str.contains('(^nan$|Not Listed|found this comment helpful)')].index
df_all.drop(bad_indices, inplace=True)
df_all.reset_index(drop=True)
conditions_w_most_drugs = df_all.groupby(['condition'])['drugName'] \
                          .nunique() \
                          .sort_values(ascending=False)[1:n_conditions+1]

fig, ax = plt.subplots(1, 1, figsize=(16, 6), dpi=200)
condition_arr = []
for i, (condition, count) in enumerate(conditions_w_most_drugs.items()):
    condition_arr += count*[condition]
    tmp_df = pd.DataFrame(condition_arr, columns=['condition'])
g = sns.countplot(x='condition', data=tmp_df, ax=ax)
g.set_xlabel(g.get_xlabel(), fontsize=22)
g.set_ylabel(g.get_ylabel(), fontsize=22, labelpad=10)
ylabs = g.get_yticklabels()
plt.setp(ax.get_xticklabels(), rotation=45, ha='right', fontsize=16)
plt.setp(ax.get_yticklabels(), fontsize=16)
g.set_title('Medical conditions with the most number of unique drugs addressing them',y=1.05, fontsize=28)
sns.despine(left=False)</pre></code>
                <div style="text-align:center">
                <a id="fig7" style="font-size: 1.5em;">Figure 8</a>
                </div>
                <p class="text-align: center;">
                  <img src="output_28_0.png" style="width: 100%; display: block; margin: 10px auto 20px;"/>
                </p>
                <h4 id="usefulcount_rating">Variation of <code>usefulCount</code> with <code>rating</code></h4>
                <p>
                  One of the questions that I had was whether the positiveness/negativeness of the rating influence the number of peole that find the review useful?
                <pre class="prettyprint lang-language"><code class="language-python">f, ax = plt.subplots(1, 1, figsize=(14, 6), dpi=200)
g = sns.boxplot(y='usefulCount', x='rating',data=df_all, 
                ax=ax, palette="Paired", showmeans=True, 
                showfliers=False)
g.set_title('The distribution of usefulCount for different drug ratings.'+
            '\n(outliers are not shown)', fontsize=24, y=1.02);</code></pre>
                <div style="text-align:center">
                  <a id="fig8" style="font-size: 1.5em;">Figure 9</a>
                </div>
                <p class="text-align: center;">
                  <img src="output_29_0.png" style="width: 100%; display: block; margin: 10px auto 20px;"/>
                </p>
                <p>
                  I find this result really interesting. What we can infer from it is that <strong>a positive review is more likely to be found useful than a negative review by others who read the review</strong>. 
                </p>
                <p>
                  As we observed in <a href="#fig2">Figure 2</a>, the highly-rated reviews are more frequent compared to the poorly-rated ones. We need to <strong>define a metric</strong> for a <strong><font color='green'>positive</font></strong> vs. <strong><font color='red'>negative</font></strong> to be able to further inspect the quality of the reviews. Gouping the reviews into positive and negative categories can shed light on the correlation of the review ratings with more than just one other feature.
                  For now, we classify the reviews with rating below 5.5 as <strong><font color='red'>negative</font></strong> and otherwise <strong><font color='green'>positive</font></strong>.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">df_all['rating_binary'] = df_all['rating'].apply(lambda x: 'positive' if x>5.5 else 'negative')
print("The dataset includes {0:d} positive and {1:d} negative reviews" \
      .format(len(df_all[df_all["rating_binary"]=="positive"]), \
              len(df_all[df_all["rating_binary"]=="negative"])))</code></pre>
                <pre>The dataset includes 148682 positive and 63424 negative reviews</pre>
                <pre class="prettyprint lang-language"><code class="language-python">df_all.head()</code></pre>
                <table class="table table-striped">
                  <thead>
                    <tr style="text-align: right;">
                      <th></th>
                      <th>uniqueID</th>
                      <th>drugName</th>
                      <th>condition</th>
                      <th>review</th>
                      <th>rating</th>
                      <th>date</th>
                      <th>usefulCount</th>
                      <th>year</th>
                      <th>month</th>
                      <th>rating_binary</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <th score="row">0</th>
                      <td>206461</td>
                      <td>Valsartan</td>
                      <td>Left Ventricular Dysfunction</td>
                      <td>"It has no side effect, I take it in combinati...</td>
                      <td>9</td>
                      <td>2012-05-20</td>
                      <td>27</td>
                      <td>2012</td>
                      <td>5</td>
                      <td>positive</td>
                    </tr>
                    <tr>
                      <th score="row">1</th>
                      <td>95260</td>
                      <td>Guanfacine</td>
                      <td>ADHD</td>
                      <td>"My son is halfway through his fourth week of ...</td>
                      <td>8</td>
                      <td>2010-04-27</td>
                      <td>192</td>
                      <td>2010</td>
                      <td>4</td>
                      <td>positive</td>
                    </tr>
                    <tr>
                      <th score="row">2</th>
                      <td>92703</td>
                      <td>Lybrel</td>
                      <td>Birth Control</td>
                      <td>"I used to take another oral contraceptive, wh...</td>
                      <td>5</td>
                      <td>2009-12-14</td>
                      <td>17</td>
                      <td>2009</td>
                      <td>12</td>
                      <td>negative</td>
                    </tr>
                    <tr>
                      <th score="row">3</th>
                      <td>138000</td>
                      <td>Ortho Evra</td>
                      <td>Birth Control</td>
                      <td>"This is my first time using any form of birth...</td>
                      <td>8</td>
                      <td>2015-11-03</td>
                      <td>10</td>
                      <td>2015</td>
                      <td>11</td>
                      <td>positive</td>
                    </tr>
                    <tr>
                      <th score="row">4</th>
                      <td>35696</td>
                      <td>Buprenorphine / naloxone</td>
                      <td>Opiate Dependence</td>
                      <td>"Suboxone has completely turned my life around...</td>
                      <td>9</td>
                      <td>2016-11-27</td>
                      <td>37</td>
                      <td>2016</td>
                      <td>11</td>
                      <td>positive</td>
                    </tr>
                  </tbody>
                </table>
                <p>
                  I use <a href="https://seaborn.pydata.org/index.html"><code>Seaborn</code></a>'s <a href="https://seaborn.pydata.org/generated/seaborn.boxenplot.html"><code>boxenplot()</code></a> (or <a href="https://vita.had.co.nz/papers/letter-value-plot.html">Letter-value plot</a>) for visualization. It can be thought of as an extension of boxplot that is more convenient for large data as it offers more precise estimates of quantiles beyond the quartiles which might be important but missed when using boxplot. Furthermore, I include two plots for this part where the first plot (<a href="#fig9">Figure 10</a>) shows the data where the top and bottom 0.01% of the population are removed and the second plot (<a href="#fig10">Figure 11</a>) shows the full data.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">f, ax = plt.subplots(1, 1, figsize=(14, 14), dpi=200)
sns.set_style('dark')
bar_width = 0.8
q_low = df_all["usefulCount"].quantile(0.01)
q_hi  = df_all["usefulCount"].quantile(0.99)
df_outliers_removed = df_all[(df_all["usefulCount"] < q_hi) &#038; (df_all["usefulCount"] > q_low)]
means_positive = df_all[df_all['rating_binary']=='positive'].groupby('year')['usefulCount'].mean()
means_negative = df_all[df_all['rating_binary']=='negative'].groupby('year')['usefulCount'].mean()
means = np.hstack([means_positive,means_negative])
g = sns.boxenplot(x="year", y="usefulCount", hue="rating_binary",width=bar_width,
                  palette="pastel", data=df_outliers_removed, ax=ax)
g.set_xlabel(g.get_xlabel(), fontsize=18)
g.set_ylabel(g.get_ylabel(), fontsize=18)
for i,mu in enumerate(means):
    shift = bar_width/4*pow(-1,i+1); # shift left for positive, right for negative
    g.text(i//2+shift, mu, f"{np.round(mu,1)}", 
           fontdict={'color':'black', 'fontsize':10}, rotation=0, ha='center', va='center',
           bbox=dict(facecolor='white', alpha=0.4, edgecolor=None))
plt.legend(bbox_to_anchor=(0.5, 1.05), loc='center', borderaxespad=0., title='rating binary')
g.set_title('Distribution of usefulCount for positive and negative reviews in each year.\n'+
            '(outliers removed)', fontsize=24, y=1.1);</code></pre>
                <div style="text-align:center">
                <a id="fig9" style="font-size: 1.5em;">Figure 10</a>
                </div>
                <p class="text-align: center;">
                  <img src="output_31_0.png" style="width: 100%; display: block; margin: 10px auto 20px;"/>
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">f, ax = plt.subplots(1, 1, figsize=(14, 28), dpi=200)
sns.set_style('dark')
bar_width = 0.8
means_positive = df_all[df_all['rating_binary']=='positive'].groupby('year')['usefulCount'].mean()
means_negative = df_all[df_all['rating_binary']=='negative'].groupby('year')['usefulCount'].mean()
means = np.hstack([means_positive,means_negative])
g = sns.boxenplot(x="year", y="usefulCount", hue="rating_binary",width=bar_width,
                  palette="pastel", data=df_all, ax=ax)
g.set_xlabel(g.get_xlabel(), fontsize=18)
g.set_ylabel(g.get_ylabel(), fontsize=18)
for i,mu in enumerate(means):
    shift = bar_width/4*pow(-1,i+1); # shift left for positive, right for negative
    g.text(i//2+shift, mu, f"{np.round(mu,1)}", 
           fontdict={'color':'black', 'fontsize':10}, rotation=0, ha='center', va='center',
           bbox=dict(facecolor='white', alpha=0.4, edgecolor=None))
plt.legend(bbox_to_anchor=(0.5, 1.02), loc='center', borderaxespad=0., title='rating binary')
plt.setp(ax.get_xticklabels(), fontsize=14)
plt.setp(ax.get_yticklabels(), fontsize=14)
g.set_title('Distribution of usefulCount for positive and negative reviews in each year', fontsize=24, y=1.04);</code></pre>
                <div style="text-align:center">
                  <a id="fig10" style="font-size: 1.5em;">Figure 11</a>
                </div>
                <p class="text-align: center;">
                  <img src="output_35_0.png" style="width: 100%; display: block; margin: 10px auto 20px;"/>
                </p>
                <p>
                  There are some interesting detils tht are revealed using Figures <a href="#fig9">9</a> and <a href="#fig10">10</a>.
                </p>
                <ul>
                  <li>
                    In support of the point brought up previously, that <em>positive reviews are more likely to be found useful</em>, we can see that the mean <code>usefulCount</code> for positive reviews is higher than that of the negative reviews in 8 out of 10 years (every year except 2010 and 2015).
                  </li>
                  <li>
                    2012 and 2014 are the only years where the mean of <code>usefulCount</code> is lower than its median for both positive and negative reviews (same for negative reviews of 2008). What this tells us is that there are 
                  </li>
                  <li>
                    The median of <code>usefulCount</code> for positive reviews is higher than that of the negative reviews for all years.
                  </li>
                  <li>
                    Note that hwo excluding the reviews with very high <code>usefulCount</code> can influence our interpretation. In this specific project, the reviews with high <code>usefulCount</code> can't and shouldn't be excluded because they are simply <strong>not outliers</strong>.
                  </li>
                  <li>
                    The reason why almost all the outliers (denoted by the diamond symbol) in both figures <a href="#fig9">9</a> and <a href="#fig10">10</a> correspond to the observations with high <code>usefulCount</code> is that there are a lot of reviews where <code>usefulCount=0</code> and in fact a quick investigation shows that the number of observations with <code>usefulCount=0</code> is more than 1% of all the reviews. This is also the reason behind the mean of the population dropping for all the situations (The <code>usefulCount</code> can't be negative!)
                  </li>
                <pre class="prettyprint lang-language"><code class="language-python">pct = abs((len(df_all[(df_all["usefulCount"] &gt; q_low)])-len(df_all))/len(df_all))*100
print(f"{pct:.1f}%")</code></pre>
<pre>3.8%</pre>     
                  <li>
                    Note that the number of reviews that were useful, be it positive or negative, declines with time which is expected because the older reviews are read more and there are not a lot of new drugs joining the market every year.
                  </li>
                </ul>
                <h2 id="sentiment_analysis">Sentiment Analysis</h2>
                <p>
                  <strong>Sentiment analysis</strong> is the process of analyzing text/voice data using <a href="/wiki/Natural_language_processing" title="Natural language processing">natural language processing (NLP)</a>, <a href="/wiki/Text_analytics" class="mw-redirect" title="Text analytics">text analysis</a>, and <a href="/wiki/Computational_linguistics" title="Computational linguistics">computational linguistics</a> to extract and determine the emotional tone, attitude, or opinion carried by the data. The use of sentiment analysis is common in areas such as healthcare, social media, and marketing to study surveys, reviews, user comments, customer text/voice etc.
                </p>
                <h3 id="data_preparation_for">Data preparation for sentiment analysis</h3>
                <h4 id="stopwords">Stopwords</h4>
                <p>
                   <strong>stopwords</strong> are words that we do not want them taking up space in our database, or taking up valuable processing time. For this, we can remove them easily by storing a list of words that we consider to be stop words. Even though when it comes to <strong><em>sentiment analysis</em></strong> the popular opinion is to remove <strong>stopwords</strong>, removing them is <strong>not always the best idea, especially if the context of the phrases may influence the performance of the algorithm</strong>. 
                </p>
                <p>
                   For now we will remove the <strong>stopwords</strong> from the <code>review</code> column but we first <strong><em>make sure that the ones that carry an emotional meaning are not removed</em></strong> as they are important for sentiment analysis; For instance, there are many words (see below) with <strong>negative connotation</strong> that are required to be <strong>removed them from the stopwords</strong>:
                </p>
                <table class="table table-striped" style="margin: auto; width: fit-content;padding-bottom: 1em;">
                  <tbody>
                    <tr>
                      <td>aren't</td>
                      <td>haven't</td>
                      <td>not</td>
                    </tr>
                    <tr>
                      <td>couldn't</td>
                      <td>isn't</td>
                      <td>can't</td>
                    </tr>
                    <tr>
                      <td>didn't</td>
                      <td>mightn't</td>
                      <td>shan't</td>
                    </tr>
                    <tr>
                      <td>doesn't</td>
                      <td>mustn't</td>
                      <td>shouldn't</td>
                    </tr>
                    <tr>
                      <td>don't</td>
                      <td>needn't</td>
                      <td>wasn't</td>
                    </tr>
                    <tr>
                      <td>hadn't</td>
                      <td>no</td>
                      <td>weren't</td>
                    </tr>
                    <tr>
                      <td>hasn't</td>
                      <td>nor</td>
                      <td>wouldn't</td>
                    </tr>
                  </tbody>
                </table>
                <h4 id="cleaning_tokenization">Cleaning, tokenization, and stemming</h4>
                <p>
                  We already scanned the reviews to remove unwanted <code class="language">html</code> characters using the <code>'html.parser'</code> of <code class="library">BeautifulSoup</code>. However, there is some further cleaning necessary besides the removal of unwanted characters. We also need to <strong>tokenize</strong> the <strong>reviews</strong>, i.e. <em>break it up to pieces</em> such as <strong>words, keywords, phrases, symbols</strong> etc. before sttempting to train the model for <em>Sentiment Analysis</em>.
                </p>
                <p>
                  We will define a simple function for text-cleaning, tokenization, and removal of the important negative verbs from the list of <strong>stopwords</strong>. We also take advantage of <code class="library">nltk</code>'s <strong>stopwords</strong> library to make sure all the unwanted words are removed from the reviews. Lastly, we use <code class="library">nltk</code>'s <code class="method">SnowballStemmer</code> which is meant to <a href="https://www.nltk.org/howto/stem.html">remove morphological affixes from words, leaving only the word stem</a>. This can reduce the computation cost significantly.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">from wordcloud import WordCloud, STOPWORDS
import nltk
from nltk import PorterStemmer as Porter_stemmer
from nltk.corpus import stopwords
from nltk.stem.snowball import SnowballStemmer
from bs4 import BeautifulSoup
nltk.download('stopwords')
Snowball_stemmer = SnowballStemmer('english', ignore_stopwords=True)
nltk_stopwords = stopwords.words('english')
stopWords = STOPWORDS.union(nltk_stopwords)
remove_from_stopWords = ["aren't", "couldn't", "didn't", "doesn't", "don't", "hadn't", "hasn't",
                         "haven't", "isn't", "mightn't", "mustn't", "needn't", "no", "nor", "not",
                         "can't", "shan't", "shouldn't", "wasn't", "weren't", "wouldn't"]

for i in remove_from_stopWords:
    stopWords.remove(i)

def clean_review(raw_review, stopWords=stopWords, stemmer=Snowball_stemmer):
    
    # 1. Substitute all non-letter characters with a space
    letters_only = re.sub('[^a-zA-Z]', ' ', review_text)
    
    # 2. lower letters and remove spaces
    words = letters_only.lower().split()
    
    # 3. Stopwords 
    meaningfulWords = [w for w in words if not w in stopWords]
    
    # 4. Stemming
    stemming_words = [stemmer.stem(w) for w in meaningfulWords]
    # having
    # had     ======> have
    # have
    
    # 5. space join words and return
    return( ' '.join(stemming_words))</code></pre>
                <p>
                  We can run a quick sanity check!
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">print(df_train['review'][110])</code></pre>
                <pre>"Been dealing with restless leg syndrome.for about 2 years. It kept me from falling asleep. First they gave me flexiril. And it did nothing. Than a miracle came about and I was prescribed reprinol and my legs haven't twitched since . Amazing drug I must say. My sleep has improved greatly"</pre>
                <pre class="prettyprint lang-language"><code class="language-python">print(clean_review(df_train['review'][110]))</code></pre>
                <pre>deal restless leg syndrom year kept fall asleep first gave flexiril noth miracl came prescrib reprinol leg twitch amaz drug must say sleep improv great</pre>
                <p>
                  Note that not all the words are going to look meaningful since we see the stems.
                </p>
                <h4 id="wordcloud">WordCloud</h4>
                <p>
                  <strong>wordcloud</strong> is a nice way to visually represent of words. I use python's <code class="library"><a href="https://amueller.github.io/word_cloud/">WordCloud</a></code> library for this purpose. We can take a look at most frequent words in positive and negative reviews using a customized wordcloud function.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">def cloud_of_words(text_df, mask=None, fig_size=(16, 5), collocations=True,
                   max_words=150, width=800, height=250, background_color="#006666",
                   stopWords=None, relative_scaling=0, title='word cloud', 
                   title_size=28, random_state=None, max_font_size=100, colormap=None):

    wordcloud = WordCloud(stopwords=stopWords, max_words=max_words, collocations=collocations,
                          max_font_size=max_font_size, random_state=random_state,
                          width=width, height=height, mask=mask, background_color=background_color,
                          colormap=colormap, relative_scaling=relative_scaling).generate(str(text_df))

    plt.figure(figsize=fig_size)
    plt.imshow(wordcloud)
    plt.title(title, fontsize=title_size, y=1.02)
    plt.axis('off')
    plt.tight_layout()</code></pre>
                <p>
                  We can now visualize the wordcloud of positive
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">cloud_of_words(df_all[df_all['rating_binary']=='positive']['review'], 
               stopWords=stopWords, 
               title='Frequent words in positive reviews', 
               colormap='magma', 
               background_color='steelblue')</code></pre>
               <div style="text-align:center">
                  <a id="fig11" style="font-size: 1.5em;">Figure 12</a>
               </div>
               <p class="text-align: center;">
                 <img src="output_54_0.png" style="width: 100%; display: block; margin: 10px auto 20px;"/>
               </p>
                <p>
                  and negative reviews.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">cloud_of_words(df_all[df_all['rating_binary']=='negative']['review'], 
               stopWords=stopWords, 
               title='Frequent words in negative reviews', 
               colormap='autumn')</code></pre>
                <div style="text-align:center">
                   <a id="fig12" style="font-size: 1.5em;">Figure 13</a>
                </div>
                <p class="text-align: center;">
                  <img src="output_56_0.png" style="width: 100%; display: block; margin: 10px auto 20px;" />
                </p>
                <h3 id="language_models">Language Models</h3>
                <h4 id="bag_of_words">Bag of words</h4>
                <p>
                  <strong>Bag of words</strong> is one of the simplest yet commonly used language models that represents a sentence as the <em>multiset</em> of the words forming the sentence. <em>multiset</em> meaning that even though the model disregards grammar and word order, it cares about the number of instances that each word is used in the sentence. The main idea behind this model is that the sentences sharing more words in common are more likely to belong to the same class, e.g., <em>positive vs. negative</em> classes.
                </p>
                <p>
                  <code class="module">CountVectorizer</code> modules of <code class="library">sklearn</code> is one of the easiest way to build a bag-of-words model. Let's take a look at a simple demonstration:
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">docs = ['Today is a nice day.',
        'I love reading science fiction books.',
        'Are you coming to Al\'s wedding reception tonight?',
        'We are going to analyze these documents',
        'The storyline was not as great as the acts.',
        'Nice job kids! Moving on to the next game!',
        'I am good at things I never do!']
docs_vectorizer = CountVectorizer()
X = docs_vectorizer.fit_transform(docs) 
# X is the vectorized matrix where each row corresponds to a sentence and each column 
# corresponds to a word. Every elemnt X_ij shows the number of times word "j"
# is used in document "i". In this case, we have 7 sentences.
print(X.shape)</code></pre>
<pre>(7, 41)</pre>
                <pre class="prettyprint lang-language"><code class="language-python"># features
print(docs_vectorizer.get_feature_names())</code></pre>
                <pre>['acts', 'al', 'am', 'analyze', 'are', 'as', 'at', 'books', 'coming', 'day', 'do', 'documents', 'fiction', 'game', 'going', 'good', 'great', 'is', 'job', 'kids', 'love', 'moving', 'never', 'next', 'nice', 'not', 'on', 'reading', 'reception', 'science', 'storyline', 'the', 'these', 'things', 'to', 'today', 'tonight', 'was', 'we', 'wedding', 'you']</pre>
                <p>
                  Note that <code>CountVectorizer</code> doesn't care about the noisy words such as <code>["on", "at", "to", "am"]</code> etc. which appear a lot but don't help much with extraxting the emotions from the review.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python"># matrix
X.toarray()</code></pre>
                <pre>array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,
        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1],
       [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0],
       [1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
        0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,
        0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0],
       [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])
      </pre>    
                <p>
                  Here's one way to see how the matrix represents the words in the documents:
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">doc1_binary_ids = X.toarray()[0,:]
doc1_ids = np.where(doc1_binary_ids>0)
features_arr = np.asarray(docs_vectorizer.get_feature_names())
features_arr[doc1_ids]</pre></code>
<pre>array(['day', 'is', 'nice', 'today'])</pre>
                <p>
                  We can see that <code>CountVectorizer</code> does not maintain the word order. In large datasets like our dataset, noisy words reflect very little insigh about the document contents. Therefore, using count data as is to train a classifier causes these frequent but useless terms shadow the frequencies of rarer yet relevant terms that carry a lot of information about the review context. <strong>Term-Frequency Inverse Document-Frequency (TF-IDF)</strong> is one way of handling such situations. $\text{tf-idf(t,d)}$ is TF-IDF of the term $t$ in the document $d$ and is defined as:
                </p>
$$
\text{tf-idf(t,d)}=\text{tf(t,d)} \times \text{idf(t)}
$$
                <p>
                  where <strong>Term Frequency (TF)</strong> $\text{tf(t,d)}$ is <strong>the number of times the term $t$ occurs in the document $d$</strong> and <strong>Inverse Document-Frequency (IDF)</strong> $\text{idf(t)}$ is computed as:
                </p>
$$
\text{idf}(t) = \log{\dfrac{1 + n}{1+\text{df}(t)}} + 1.
$$              
                <p>
                  <strong>Document Frequency</strong> $\text{df}(t)$ accounts for the count of those documents containing the term $t$ and $n$ is the total number of documents in the data. TF-IDF is usually normalized by the <strong>Euclidean norm</strong> as:
                </p>
$$
\text{tf}^{\, L_2-\text{ norm}}(t,d) = \dfrac{\text{tf}(t,d)}{\sqrt{\sum\limits_{\text{term}}^{\text{all terms}} \text{tf}(\text{term},d)^2}}
$$              
                <p>
                  <strong>Note</strong>: <code class="library">sklearn</code> slightly tweaks the definition of $\text{idf(t)}$ as:
$$
\text{idf}(t) = \log{\dfrac{n}{1+\text{df}(t)}}.
$$  
                </p>
                <p>
                  Finally, setting the <code class="arg">smooth_idf</code> argument of <code class="library">sklearn</code>'s <code class="module">TfidfVectorizer</code> to <code class="bool">False</code> changes the above definition to:
                </p>
$$
\text{idf}(t) = \log{\dfrac{n}{\text{df}(t)}}+1.
$$ 

<!-- The main limitation of this approach is that it does not take into account the relative position of words within the document. Here we are only using the frequency of occurence. Nevertheless, it works pretty well for this data set. -->
               <h4 id="n-grams">n-grams</h4>
                <p>
                   <strong>n-gram</strong> is a contiguous sequence of n items from a given sample of text or speech (<a href="https://en.wikipedia.org/wiki/N-gram">ref</a>). <strong>n-gram</strong>s are widely used in <strong>NLP</strong> for applications such as spelling correction, word breaking and text summarization. The following table shows the n-gram representation of <em>"This is a beautiful present!"</em> for n=1 (<em>unigram</em>), n=2 (<em>bigram</em>), n=3 (<em>trigram</em>), and n=4(<em>4</em>-gram). 
                </p>
                <table class="table table-striped" style="margin: auto; width: fit-content;padding-bottom: 1em;">
                  <thead>
                    <tr style="text-align: left;">
                      <th>unigram</th>
                      <th>bigram</th>
                      <th>trigram</th>
                      <th>4-gram</th> 
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>This</td>
                      <td>This is</td>
                      <td>This is a</td>
                      <td>This is a beautiful</td>
                    </tr>
                    <tr>
                      <td>is</td>
                      <td>is a</td>
                      <td>is a beautiful</td>
                      <td>is a beautiful present!</td>
                    </tr>
                    <tr>
                      <td>a</td>
                      <td>a beautiful</td>
                      <td>a beautiful present!</td>
                      <td></td>
                    </tr>
                    <tr>
                      <td>beautiful</td>
                      <td>beautiful present!</td>
                      <td></td>
                      <td></td>
                    </tr>
                    <tr>
                      <td>present!</td>
                      <td></td>
                      <td></td>
                      <td></td>
                    </tr>
                  </tbody>
                </table>
                <p>
                  Next, we define a simple function to generate <em>n-grams</em>. We will use this function later on in our training pipeline.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">def gen_n_grams(sentence, n=4, stopWords=stopWords):
    token = [token for token in sentence.lower().split(
        ' ') if token != '' if token not in stopWords]
    n_grams = zip(*[token[i:] for i in range(n)])
    return [' '.join(gram) for gram in n_grams]

gen_n_grams('The beautiful moment that all of us have been waiting for has finally arrived!')</code></pre>
                <pre>['beautiful moment us waiting',
 'moment us waiting finally',
 'us waiting finally arrived!']</pre>
                <p>
                  Note that the stopwords are removed before the <em>n-grams</em> are generated.
                </p>
                <h5 id="visualizing_most_frequent">Visualizing most frequent <em>n-grams</em></h5>
                <p>
                  We first create a dictionary to store the n-grams of lengths 1 to 5.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">from collections import defaultdict
import time
frequency_dict = defaultdict(int)
review_categories = ['positive', 'negative']
grams = [1, 2, 3, 4, 5]

# initialize the dictionaries
for review_category in review_categories:
    frequency_dict[review_category]={}
    for n in grams:
        frequency_dict[review_category][n]={}
print(frequency_dict)</code></pre>
                <pre>defaultdict(<class 'int'>, {'positive': {1: {}, 2: {}, 3: {}, 4: {}, 5: {}}, 'negative': {1: {}, 2: {}, 3: {}, 4: {}, 5: {}}})</pre>
                <p>
                  Now we can populate the dictionary with the n-grams as keys and the number of times they have been observed as the values.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">for review_category in review_categories:
    start = time.time()
    for [review,rating] in df_all[df_all['rating_binary']==review_category].iloc[:,[3,4]].values:
        for n in grams:
            for ngram in gen_n_grams(clean_review(review), n):
                frequency_dict[review_category][n][ngram] = frequency_dict[review_category][n].get(ngram, np.array([1,rating])) + np.array([1,rating]) 
    print(f"done with {review_category} reviews. took {time.time()-start:.2f} seconds!")
# save the dictionary
f = open("grams_dict.pkl", "wb")
pickle.dump(frequency_dict, f)
f.close()</code></pre>
                <pre>done with positive reviews. took 360.87 seconds!
done with negative reviews. took 147.21 seconds!</pre>
                <p>Finally, we can visualize the most frequent n-grams for different values of n.</p>
<pre class="prettyprint lang-language"><code class="language-python">sns.set(rc={'axes.facecolor':'whitesmoke', 'figure.facecolor':'silver', 'legend.facecolor':'white'})
fig, ax = plt.subplots(5, 2, figsize=(12,20), dpi=400)
review_categories = ['positive', 'negative']
grams = [1, 2, 3, 4, 5]
n_most_frequent = 10
colors = ['g', 'r']
fig.tight_layout()
plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=1.2, hspace=0.4)
for i,review_category in enumerate(review_categories):
    for j,gram in enumerate(grams):
        
        values = np.asarray(sorted(frequency_dict[review_category][gram].items(), 
                                   key=lambda x: x[1][0], reverse=True)[:n_most_frequent])
        val_data = np.hstack([values[:,0].reshape(-1,1), 
                   np.vstack(
                       [values[:,1].reshape(-1,1).flatten()[i] for i in range(n_most_frequent)])]
                 )
        data=pd.DataFrame(data=val_data, columns=['review','review count','total rating'])
        data['avg_rating']=data['total rating']/data['review count']
        data['binray_review']=[review_category]*len(data)
        sns.set_color_codes("pastel")
        sns.barplot(x="review count", y="review", data=data,
                    color=colors[i], ax=ax[j][i])
        ax[j][i].set_ylabel('')
        ax[j][i].set_title(f"{gram}-grams ({review_category} reviews)", y=1.02, fontsize=20)
        ax[j][i].set_xlabel(ax[j][i].get_xlabel(), fontsize=18)
        plt.setp(ax[j][i].get_xticklabels(), fontsize=16)
        plt.setp(ax[j][i].get_yticklabels(), fontsize=16)
plt.suptitle('Most frequent n-grams in positive and negative reviews', fontsize=24, y=1.05)</code></pre>
                <div style="text-align:center">
                   <a id="fig14" style="font-size: 1.5em;">Figure 14</a>
                </div>
                <p class="text-align: center;">
                  <img src="fig14.png" style="width: 100%; display: block; margin: 10px auto 20px;"/>
                </p>
                <p>
                  By looking at <a href="#fig14">Figure 14</a> above, we note that 4-grams are the shortest of the n-grams to differentiate between the positive and negative reviews. For instance, we notice that the group of phrases such as <code>[<em>'month', 'take', 'day', 'not', ...</em>]</code> in 1-grams, <code>[<em>'side effect', 'birth control', 'mood swing', ...</em>]</code> in 2-grams, and <code>[<em>'no side effect', 'bad side effect', 'birth control pill', ...</em>]</code> in 3-grams are common among the most frequent $n$-grams in both positive and negative reviews. Looking at 5-grams shows that they could be a good candidate to train a neural network model, as we will see later in the project. 
                </p>
                <h4 id="feature_engineering">Feature Engineering</h4>
                <p>
                  We extracted month, year and weekday from review data as a part of <strong>Feature Engineering</strong> and to visually inspect the potential correlations between these features and the review qulity. 

                  Before building the models, we do some extra bit of <strong>Feature Engineering</strong> by including some characteristics of the patient reviews as new features. The new features include the review word count (<code>review_w_count</code>), the number of unique words (<code>unique_w_count</code>), and the mean word length (<code>mean_word_len</code>). Even though it makes more sense to calculate both features from raw review, we calculate them using the cleaned review for the sake of time.
                </p>
<pre class="prettyprint lang-language"><code class="language-python">df_all['review_w_count']=df_all["review"].apply(lambda review: len(review.split()))
df_all['unique_w_count']=df_all["review"].apply(lambda review: len(set(review.split())))
df_all["mean_w_len"] = df_all["review"].apply(lambda review: np.mean([len(word) for word in review.split()]))</code></pre>
                <p>
                  Next, we drop the <code>date</code> column because it's redundant. We also remove the <code>uniqueID</code> because it's useless in the context of this project.
                </p>
<pre class="prettyprint lang-language"><code class="language-python">df_all.drop(columns=['date','uniqueID'], inplace=True)</code></pre>
                <p>
                  Finally, I also decided to quantify the reviews using the <code class="module">sentiment.polarity</code> module of <code class="library">textblob</code> library. The outcomes area number between 0 and 1 so I rescale them to an integer in the range 1 to 10. I do this so that I can assess how it correlates with the review ratings in the next part.
                </p>
<pre class="prettyprint lang-language"><code class="language-python">df_all['tb_sentiment_polarity'] = df_all['review'].apply(lambda review: TextBlob(review).sentiment.polarity)</code></pre>
                <h5 id="correlation_plot">Correlation Plot</h5>
                <p>
                  We can now look at the potential correlation between the numerical variables of the model. We digitize the <code>rating_binary</code> column so that we can include it in the matrix. 
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">df_all['rating_binary'] = df_all['rating'].apply(lambda rating: 1 if rating > 5 else 0)
fig, ax = plt.subplots(1, 1, figsize=(14,14))
corr = df_all.select_dtypes(include = 'int64').corr()
g = sns.heatmap(
    corr, 
    vmin=-1, vmax=1, center=0,
    cmap='Spectral',
    square=True,
    ax=ax,
    cbar_kws={'shrink': 0.8}
)
plt.setp(ax.get_xticklabels(), rotation=45, horizontalalignment='right')
ax.set_title('Correlation Matrix', fontsize=18, y=1.02);</code></pre>
                <div style="text-align:center">
                   <a id="fig15" style="font-size: 1.5em;">Figure 15</a>
                </div>
                <p class="text-align: center;">
                  <img src="fig15.png" style="width: 100%; display: block; margin: 10px auto 20px;"/>
                </p>
                <p>
                  Let's go through the correlations that we see in <a href="#fig15">Figure 15</a> one by one:
                  <ul>
                    <li>The strong correlations between <code>rating_binary</code> and <code>rating</code> is expected as the former is derived from the latter</li>
                    <li>As expected, the sentiment polarity score from <code>TextBlob</code> shows a semi strong correlation with the <code>rating</code> of the review.</li>
                    <li>The strong correlation between <code>review_w_count</code> and <code>unique_w_count</code> is not surprising when looking at their definitions</li>
                    <li>The weak anti-correlation between <code>year</code> and <code>rating</code> is something we observed previously in <a href="#fig5">Figure 5</a></li>
                    <li>The weak correlation of <code>year</code> with <code>unique_w_count</code> and <code>unique_w_count</code> that we are able to see thanks to feature engineering. It implies that the newer reviews are longer?!</li>
                  </ul>
                </p>
                <h3>Machine learning models for sentiment analysis</h3>
                <p>
                  We start off by asessing the performance of a simple Bayesian classifier, <code class="module">MultinomialNB()</code> and a more sophisticated <code class="module">RandomForestClassifier()</code> in <strong>identifying positive and negative</strong> reviews, simply by knowing the review column as feature. The target variable in this case would be the column <code>rating_binary</code>.
                </p>
                <p>
                  I use to common word vectorizers from <code class='library'>sklearn</code>, namely, <code class="module">CountVectorizer()</code> and <code class="module">TfidfVectorizer</code> to see how each influence the performance of the ML models.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python"># split the feature-engineered data
X_train, X_test, y_train, y_test = train_test_split(df_all.review, 
                                                    df_all.rating_binary, 
                                                    test_size=0.1,random_state=110,
                                                    stratify = df_all.rating_binary 
                                                    )

# Pipeline to serialize the vectorizer and classifier
estimators = [Pipeline([('CountVectorizer', CountVectorizer()),
                        ('Naive Bayes classifier', MultinomialNB())]
                      ), 
              Pipeline([('TfidfVectorizer', TfidfVectorizer()),
                        ('Naive Bayes classifier', MultinomialNB())]
                      ),
              Pipeline([('CountVectorizer', TfidfVectorizer()),
                        ('Random Forest classifier', RandomForestClassifier(n_estimators=100, 
                                                            random_state=42, 
                                                            max_depth = 10000, 
                                                            min_samples_split = 0.001))]
                      ),
              Pipeline([('TfidfVectorizer', TfidfVectorizer()),
                        ('Random Forest classifier', RandomForestClassifier(n_estimators=100, 
                                                            random_state=42, 
                                                            max_depth = 10000, 
                                                            min_samples_split = 0.001))]
                      )
             ]

# fit
preds = []
for i,estimator in enumerate(estimators):
    now = time()
    estimator.fit(X_train, y_train)
    preds.append(estimator.predict(X_test))
    print("took {:.2f} seconds for {} using {}".format(time()-now, 
                                                   estimator.get_params()['steps'][1][0], 
                                                   estimator.get_params()['steps'][0][0], 
                                                   ))
    print(f"train accuracy: {estimator.score(X_train, y_train)*100:.2f}%")
    print(f"test accuracy: {estimator.score(X_test, y_test)*100:.2f}%")</code></pre>
                <pre>took 10.38 seconds Naive Bayes classifier using CountVectorizer
train accuracy: 82.26%
test accuracy: 80.76%
took 10.80 seconds Naive Bayes classifier using TfidfVectorizer
train accuracy: 77.40%
test accuracy: 76.54%
took 211.20 seconds Random Forest classifier using CountVectorizer
train accuracy: 88.04%
test accuracy: 78.28%
took 243.36 seconds Random Forest classifier using TfidfVectorizer
train accuracy: 95.18%
test accuracy: 83.89%</pre>

                <p>
                  <a href="../../ML/confusion_matrix.html">Confusion matrix</a> provides a nice way to assess the performance of the machine learning models we trained in this part.
                </p>

                <pre class="prettyprint lang-language"><code class="language-python">fig, ax = plt.subplots(1, 1, figsize=(6,6), dpi=100)
labels = ["Negative", "Positive"]
y_pred = estimator.predict(X_test)
conf_mat = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_mat, xticklabels=labels, 
            yticklabels=labels, cmap="turbo", 
            annot=True, annot_kws={'fontsize':'large'}, 
            fmt="d", ax=ax, cbar=False);
ax.set_title('Confusion matrix of the Naive Bayes classifier', fontsize=18, y=1.05)
ax.set_ylabel('True class', fontsize=16, labelpad=10)
ax.set_xlabel('Predicted class', fontsize=16, labelpad=10)
plt.setp(ax.get_xticklabels(), fontsize=14)
plt.setp(ax.get_yticklabels(), fontsize=14)
plt.show()</code></pre>
                <div style="text-align:center">
                  <a id="mlclfconfmat" style="font-size: 1.5em;">Figure 16</a>
                </div>
                <p class="text-align: center;">
                  <img src="mlclfconfmat.png" style="width: 80%; display: block; margin: 10px auto 20px;"/>
                </p>
                <p>
                  <ul>
                    <li>
                      Confusion matrices suggest that <code class="module">MultinomialNB()</code> shows a better classification performance when combind with <code>CountVectorizer()</code> compared to when it's combined with <code>TfidfVectorizer()</code>. In this regard, <code class="module">RandomForestClassifier()</code> is in sharp contrast to <code class="module">MultinomialNB()</code> and it performs better when using <code>TfidfVectorizer()</code>.
                    </li>
                    <li>
                      Among the <strong>model+vectorizer</strong> combinations, <code class="module">MultinomialNB() + CountVectorizer()</code> does the best job in <strong>correctly identifying the negative reviews</strong>. However, this comes at the cost of poorer performance in identifying positive reviews with a significantly <strong>higher false negatives</strong> and <strong>lower true positives</strong>.
                    </li>
                    <li>
                      Predictions using <code class="module">RandomForestClassifier()</code> appear to be suffering from overfitting. This is easy to notice when looking at the $\approx$11% difference in performance between the train and test data. This can be remedied by reducing the complexity of the <code class="module">RandomForestClassifier()</code>, for instance, by reducing the <code>max_depth</code>.
                    </li>
                  </ul>
                </p>
                <h4>Influence of n-grams on the performance of ML classifiers</h4>
                <p>
                  In this part, we are interested to see if training the ML models using n-grams ($n\geq2$) leads to improvement in their performance.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">estimators = []
for i in range(2,6):
    estimators.append(Pipeline([('CountVectorizer', CountVectorizer(ngram_range=(i,i), 
                                                                    max_features=10000)),
                                ('Naive Bayes classifier', MultinomialNB())
                               ]
                              )
                     )
# fit
preds = []
for i,estimator in enumerate(estimators):
    now = time()
    #estimator.fit(X_train, y_train)
    preds.append(estimator.predict(X_test))
    print("took {:.2f} seconds {} using {:d}-grams".format(time()-now, 
                                                           estimator.get_params()['steps'][1][0], 
                                                           i+2)
         )
    print(f"train accuracy: {estimator.score(X_train, y_train)*100:.2f}%")
    print(f"test accuracy: {estimator.score(X_test, y_test)*100:.2f}%")</code></pre>
<pre>took 21.79 seconds Naive Bayes classifier using 2-grams
train accuracy: 82.80%
test accuracy: 82.17%
took 39.43 seconds Naive Bayes classifier using 3-grams
train accuracy: 81.30%
test accuracy: 80.55%
took 53.77 seconds Naive Bayes classifier using 4-grams
train accuracy: 78.54%
test accuracy: 77.73%
took 60.52 seconds Naive Bayes classifier using 5-grams
train accuracy: 76.02%
test accuracy: 74.72%</pre>
                <p>
                  The following table shows the summary of performances of the two ML models using n-grams.
                </p>
                <table class="table table-striped">
                  <thead>
                    <tr style="text-align: center;">
                      <th style="color: white;"></th>
                      <th colspan=4><strong><code style="color: #000;">Naive Bayes</code></strong></th>
                      <th colspan=4><strong><code style="color: #000;">Random Forest</code></strong></th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr style="text-align: center;">
                      <th scope="row">vectorizer</th>
                      <td colspan=2><code style="color: #000;">CountVectorizer</code></td>
                      <td colspan=2><code style="color: #000;">TfidfVectorizer</code></td>
                      <td colspan=2><code style="color: #000;">CountVectorizer</code></td>
                      <td colspan=2><code style="color: #000;">TfidfVectorizer</code></td>
                    </tr>
                    <tr>
                      <th scope="row">data</th>
                      <td>train</td>
                      <td>test</td>
                      <td>train</td>
                      <td>test</td>
                      <td>train</td>
                      <td>test</td>
                      <td>train</td>
                      <td>test</td>
                    </tr>
                    <tr>
                      <th scope="row">1-gram</th>
                      <td>82.26</td>
                      <td>80.76</td>
                      <td>77.40</td>
                      <td>76.54</td>
                      <td>88.04</td>
                      <td>78.28</td>
                      <td>95.18</td>
                      <td>83.89</td>
                    </tr>
                    <tr>
                      <th scope="row">2-gram</th>
                      <td>82.80</td>
                      <td>82.17</td>
                      <td>82.41</td>
                      <td>82.17</td>
                      <td>97.01</td>
                      <td>89.84</td>
                      <td>99.02</td>
                      <td>92.79</td>
                    </tr>
                    <tr>
                      <th scope="row">3-gram</th>
                      <td>81.30</td>
                      <td>80.55</td>
                      <td>81.54</td>
                      <td>80.83</td>
                      <td>92.87</td>
                      <td>86.21</td>
                      <td>95.15</td>
                      <td>88.27</td>
                    </tr>
                    <tr>
                      <th scope="row">4-gram</th>
                      <td>78.54</td>
                      <td>77.73</td>
                      <td>79.14</td>
                      <td>77.97</td>
                      <td>train acc</td>
                      <td>80.04</td>
                      <td>87.92</td>
                      <td>81.99</td>
                    </tr>
                    <tr>
                      <th scope="row">5-gram</th>
                      <td>76.02</td>
                      <td>74.72</td>
                      <td>76.51</td>
                      <td>74.90</td>
                      <td>train acc</td>
                      <td>75.80</td>
                      <td>81.60</td>
                      <td>77.22</td>
                    </tr>
                  </tbody>
                </table>
                <ul>
                  <li></li>
                  <li></li>
                  <li></li>
                  <li></li>
                </ul>
                <h3>Deep learning models for sentiment analysis</h3>
                <p>
                  In this section we develop deep learning models for sentiment analysis. In the <strong>Model Selection</strong> process, I explore different neural network architectures for sentiment analysis. Model selection is the process of fitting multiple models on a given dataset and choosing one over all others. I start with the baseline model which uses <code>CountVectorizer</code> as the encoding method which is piped into a simlple neural network. This model is the baseline model. I used <code class="library">tensorflow</code> to design the neural networks in this project. 
                </p>
                <h4>Sentiment analysis using <code>CountVectorizer</code> and a simple NN</h4>
                <p>
                  First, we split the data into train, validation, and test data and then, transform the review data into a numerical representation using<code>CountVectorizer</code>. We also save the transformed features using <code>pickle</code> and <code>bz2</code> because the transformation can take some time. This way we can use them again later as we develop the sentiment analysis models. 
                </p>
                <pre class="prettyprint lang-language"><code class="language-python"># split the feature-engineered data to train and test
X_train, X_test, y_train, y_test = train_test_split(df_all.review, 
                                                    df_all.rating_binary, 
                                                    test_size=0.1, 
                                                    random_state=110,
                                                    stratify = df_all.rating_binary 
                                                    )

# further split train to tr and validation
X_tr, X_val, y_tr, y_val = train_test_split(X_train, 
                                            y_train, 
                                            test_size=0.2, 
                                            random_state=110, 
                                            stratify = y_train
                                            )

vectorizer = CountVectorizer(analyzer = 'word', 
                             tokenizer = None,
                             preprocessor = None, 
                             stop_words = None, 
                             max_features = 10000
                            )
# transform
vectorizer.fit(X_train)
vectorized_features_train = vectorizer.transform(X_train)
vectorized_features_tr = vectorizer.transform(X_tr)
vectorized_features_val = vectorizer.transform(X_val)
vectorized_features_test = vectorizer.transform(X_test)

# save the vectorized features
with bz2.open('CountVect_10000_train.pkl.bz2', 'wb') as f:
    pickle.dump(vectorized_features_train, f)
f.close()
with bz2.open('CountVect_10000_tr.pkl.bz2', 'wb') as f:
    pickle.dump(vectorized_features_tr, f)
f.close()
with bz2.open('CountVect_10000_val.pkl.bz2', 'wb') as f:
    pickle.dump(vectorized_features_val, f)
f.close()
with bz2.open('CountVect_10000_test.pkl.bz2', 'wb') as f:
    pickle.dump(vectorized_features_test, f)
f.close()

# to load:
# with bz2.open('file.pkl.bz2', 'rb') as f:
#     vectorized_features = pickle.load(f)
# f.close()</code></pre>

                <p>
                Next, we build the neural network. I used <code class="method">SGD()</code> as the optimizer with <code>lr=0.005</code>.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">opt = SGD(lr=0.005)
# Build the model 

model = Sequential(name='baseline')

model.add(Dense(400, input_shape=(10000,)))# hidden layer 1
model.add(Activation('relu'))

model.add(Dense(100, activation='relu'))# hidden layer 2
model.add(Dense(units=1, activation='sigmoid'))# output layer
model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])
model.summary()</code></pre>
<pre>Model: "baseline"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 400)               4000400   
_________________________________________________________________
activation (Activation)      (None, 400)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 100)               40100     
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 101       
=================================================================
Total params: 4,040,601
Trainable params: 4,040,601
Non-trainable params: 0
_________________________________________________________________</pre>
                <p>
                  We are redy to train the model! I use a <code>ModelCheckpoint</code> that tracks <code>'val_loss'</code> and saves the model weights at the iteration with the minimum validation loss. In addition, I used <strong>early stopping</strong> with validation loss as the stopping criteria to reduce the overfitting. I used <code>100</code> epochs with <code>patience=30</code>, i.e., 100 rounds of training where the trianing stops if there's no improvement in validation loss after 30 iterations. Lastly, I define a dictionary to keep track of different model configurations and keeping track of their performances.
                </p>
<pre class="prettyprint lang-language"><code class="language-python">model_config = model.get_config()
checkpoint = ModelCheckpoint(filepath=f"{model_config['name']}.h5", monitor='val_loss', mode='min', verbose=1, 
                             save_best_only=True)
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)
callbacks_list = [checkpoint, es]
# fit model
history = model.fit(vectorized_features_tr.toarray(), y_tr, epochs=100, 
                    batch_size=64, callbacks=callbacks_list, 
                    shuffle=False, validation_data=(vectorized_features_val.toarray(), y_val))
# update the model_dict
model_config['hist']=history.history
model_dict = {}
model_dict[model_config['name']]=model_config
f = open(f"model_dict.pkl", "wb")
pickle.dump(model_dict, f)
f.close()</code></pre>
<pre>Epoch 1/100
2387/2387 [==============================] - ETA: 0s - loss: 0.5460 - accuracy: 0.7283
Epoch 00001: val_loss improved from inf to 0.48128, saving model to baseline.h5
2387/2387 [==============================] - 14s 6ms/step - loss: 0.5460 - accuracy: 0.7283 - val_loss: 0.4813 - val_accuracy: 0.7653
...
...
...
Epoch 64/100
2386/2387 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9995
Epoch 00064: val_loss did not improve from 0.27788
2387/2387 [==============================] - 14s 6ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.3521 - val_accuracy: 0.9279
Epoch 00064: early stopping</pre>
                <p>
                  Even though the validation accuracy is reasonable, there's a relatively large gap between the train and validation performances which is due to overfitting. In the next part, I'll go through my attempts to reduce overfitting by adding <code>BatchNormalization()</code> and/or <code>Dropout()</code> layers to the network architecture. 
                </p>
                <h4>Modifications to the baseline model</h4>
                <p>
                  <a href="#tab-nn-summary">Table 8</a> shows a summary of the modifications that I made to the baseline model in attempt to improve the model performance. All the models in the table used <code>SGD()</code> optimizer with <code>lr=0.005</code>.
                </p>
                <div id="tab-nn-summary">
                 <table class="table table-striped" style="display: inline-table;">
                  <caption style="font-size: 1.3em; text-align: center;">Table 8: Summary of the NN models used for drug review classification</caption><!-- - <strong>*</strong> lr=0.001 -->
                  <thead  style="background-color: #ffebe6;">
                    <tr style="text-align: left; background-color: #ffebe6;">
                      <th>Layers</th>
                      <td><strong>Baseline</strong></td>
                      <td><strong>model_00</strong></td>
                      <td><strong>model_01</strong></td>
                      <td><strong>model_02</strong></td>
                      <td><strong>model_03</strong></td>
                      <!-- <td><strong>model_04</strong><sup>*</sup></td> -->
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <th scope="row"><code class="arg">Dense(400, input_shape=(10000,))</code></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <!-- <td><span style="color: #37CF4E;">&#10004;</span></td> -->
                    </tr>
                    <tr>
                      <th scope="row" style="text-align: left;"><code class="arg">BatchNormalization()</code></td>
                      <td><span style="color: #F73100;">&#10007;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <td><span style="color: #F73100;">&#10007;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <!-- <td><span style="color: #37CF4E;">&#10004;</span></td> -->
                    </tr>
                    <tr>
                      <th scope="row" style="text-align: left;"><code class="arg">Activation('relu')</code></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <!-- <td><span style="color: #37CF4E;">&#10004;</span></td> -->
                    </tr>
                    <tr>
                      <th scope="row" style="text-align: left;"><code class="arg">Dropout</code></td>
                      <td><span style="color: #F73100;">&#10007;</span></td>
                      <td><span style="color: #F73100;">&#10007;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span>(=0.5)</td>
                      <td><span style="color: #37CF4E;">&#10004;</span>(=0.5)</td>
                      <td><span style="color: #37CF4E;">&#10004;</span>(=0.8)</td>
                      <!-- <td><span style="color: #37CF4E;">&#10004;</span>(=0.8)</td> -->
                    </tr>
                    <tr>
                      <th scope="row" style="text-align: left;"><code class="arg">Dense(100, activation='relu')</code></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <!-- <td><span style="color: #37CF4E;">&#10004;</span></td> -->
                    </tr>
                    <tr>
                      <th scope="row" style="text-align: left;"><code class="arg">Dense(units=1, activation='sigmoid')</code></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <td><span style="color: #37CF4E;">&#10004;</span></td>
                      <!-- <td><span style="color: #37CF4E;">&#10004;</span></td> -->
                    </tr>
                  </tbody>
                </table>
                <p>
                  We first load the models and make predictions for both training and validation data.
                </p>
                <pre class="prettyprint lang-language"><code class="language-python">model_names = ['baseline', 'model_00', 'model_01', 'model_02', 'model_03']
preds = []
for name in model_names:
    model = load_model(f"{name}.h5")
    preds.append(model.predict(vectorized_features_tr.toarray()))
    preds.append(model.predict(vectorized_features_val.toarray()))</code></pre>
                <p>
                  Next, we use accuracy and loss plots along with <code>confusion_matrix</code> to assess the performance of each model.
                </p>
                </div>
                <button class="btn btn-primary plus-minus-code collapsed" type="button" data-toggle="collapse" data-target="#collapsenn1" aria-expanded="false" aria-controls="collapsenn1"></button>  
<div class="collapse" id="collapsenn1" aria-expanded="true" style="height: 0px;">
                <pre class="prettyprint lang-language"><code class="language-python"># helper function
def col_to_hex(colmap, n=10, alpha=1):
    """named colormap to n hex colors"""
    out = []
    for i in range(n):
        r,g,b,_ = plt.cm.get_cmap(colmap,n)(i)
        out.append(f"#{int(r*255):02x}{int(g*255):02x}{int(b*255):02x}{int(alpha*255):02x}")
    return out

# figure, axes, and adjustments
sns.set(rc={'axes.facecolor':'silver', 'figure.facecolor':'gainsboro', 'legend.facecolor':'white'})
fig = plt.figure(figsize=(9, 25), dpi=120)
plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.3, hspace=0.75)

# Accuracy and Loss curves
gs = gridspec.GridSpec(7, 1, height_ratios=[2,2,1,1,1,1,1]) # because matplotlib is weird
ax0 = plt.subplot(gs[0]) # accuracy
ax1 = plt.subplot(gs[1]) # loss
axes=[ax0, ax1]
# labels, constants etc.
colors = col_to_hex('Dark2', n=8)
mfc = ['deepskyblue', 'orange']
titles = ['Accuracy', 'Loss']
data_label_dict = dict(zip(['loss', 'accuracy', 'val_loss', 'val_accuracy'],
                           ['tr loss', 'tr acc', 'val loss', 'val acc']))
patience = 30
n_epochs = 100
history_results = []
for i,model_name in enumerate(model_names):
    model_data_dict = model_dict[model_name]
    hist = model_data_dict['hist']
    for j,key in enumerate(hist.keys()):
        n_epochs = len(hist[key])
        start = (n_epochs+1)%2 # to reduce the number of data points displayed
        if key.endswith('y'): # accuracy
            ax_index=0
        else: # loss
            ax_index=1
        data_index=j//2 # 0:train, 1:val
        axes[ax_index].plot(np.arange(1, n_epochs+1)[start::2], hist[key][start::2], marker='o', 
                            markerfacecolor=mfc[data_index], markersize=6, color=colors[i], 
                            markeredgewidth=0, markeredgecolor=colors[i], linewidth=5, linestyle='-', 
                            label = f'{data_label_dict[key]} ({model_names[i]})')
        if key.startswith('val'): # show min val loss and the corresponding val accuracy
            axes[ax_index].plot(n_epochs-patience, hist[key][-patience-1], color='cyan', 
                                marker='x', markersize=6, markeredgewidth=3, zorder=200)
    history_results.append(hist['accuracy'][-patience-1])
    history_results.append(hist['val_accuracy'][-patience-1])
print()
for i,ax in enumerate(axes):
    ax.set_title(titles[i], fontsize=28, y=1.02)
    ax.set_xlabel('epochs', fontsize=22, labelpad=10)
    ax.legend(bbox_to_anchor=(1,1.02,0,0), loc='upper left', fontsize=14)
    ax.grid(False)
    plt.setp(ax.get_xticklabels(), fontsize=16)
    plt.setp(ax.get_yticklabels(), fontsize=16)
    
# Confusion Matrix plot
gs = gridspec.GridSpec(7, 3)
conf_mat_ax_ids = np.reshape(np.arange(9,21).reshape(4,-1), 12, order='F')
conf_mat_ax = [plt.subplot(gs[i]) for i in conf_mat_ax_ids]
# labels, constants etc.
labels = ["Negative", "Positive"]
data_labels = ['tr', 'val']
trues = [y_tr, y_val]
cbars = [False]*2*len(model_names)
cbars[-1]=True # one colorbar for all the plots
ylabels = [False]*2*len(model_names)
ylabels[0], ylabels[1] = True, True
y_ticklabel_visibility = [True, False]
for i,ax in enumerate(conf_mat_ax):
    pred = np.round(preds[i].ravel()) # probabilities to binary
    print(f"{model_names[i//2]} {data_labels[i%2]} acc: from model history={history_results[i]:.3f} - " \
        + f"from model eval={np.mean(pred==trues[i%2]):.3f}")
    conf_mat = confusion_matrix(trues[i%2].values, pred, normalize='true')
    if i>7: # new colorbar axis otherwise the confusion matrix plot will shrink!
        ax_pos = ax.get_position().bounds
        cbar_ax = fig.add_axes([(ax_pos[0]+ax_pos[2])*1.05, ax_pos[1], .02, ax_pos[3]])
        sns.heatmap(conf_mat, xticklabels=labels, 
                yticklabels=labels, cmap="YlGnBu", 
                annot=True, annot_kws={'fontsize':'x-large'}, 
                fmt=".3f", ax=ax, cbar_ax=cbar_ax, vmax=1, vmin=0)
        cbar = ax.collections[0].colorbar
        cbar.set_ticks(np.linspace(0,1,11))
        cbar.set_ticklabels([f'{x:.2f}' for x in np.linspace(0,1,11)])
    else:
        sns.heatmap(conf_mat, xticklabels=labels, 
                yticklabels=labels, cmap="YlGnBu", 
                annot=True, annot_kws={'fontsize':'x-large'}, 
                fmt=".3f", ax=ax, cbar=False)
    ax.set_title(f'{model_names[i//2]} ({data_labels[i%2]})', fontsize=20, y=1.35)
    ax.xaxis.set_label_position('top') 
    ax.xaxis.tick_top()  
    ax.yaxis.set_label_position('left') 
    ax.yaxis.tick_left()
    plt.setp(ax.get_xticklabels(), fontsize=14, rotation=0, ha='center')
    plt.setp(ax.get_yticklabels(), fontsize=14, rotation=90, va='center')
    ax.set_xlabel('Predicted class', fontsize=18, labelpad=12)
    if ylabels[i]:
        ax.set_ylabel('True class', fontsize=18, labelpad=10)</code></pre></div>
        <pre>baseline tr acc: from model history=0.988 - from model eval=0.985
baseline val acc: from model history=0.910 - from model eval=0.910
model_00 tr acc: from model history=0.895 - from model eval=0.895
model_00 val acc: from model history=0.852 - from model eval=0.852
model_01 tr acc: from model history=0.963 - from model eval=0.990
model_01 val acc: from model history=0.922 - from model eval=0.922
model_02 tr acc: from model history=0.954 - from model eval=0.981
model_02 val acc: from model history=0.911 - from model eval=0.911
model_03 tr acc: from model history=0.955 - from model eval=0.897
model_03 val acc: from model history=0.917 - from model eval=0.862</pre>
                <div style="text-align:center">
                <a id="fig17" style="font-size: 1.5em;">Figure 17</a>
                </div>
                <p class="text-align: center;">
                  <img src="NN_fig1.png" style="width: 100%; display: block; margin: 10px auto 20px;"/>
                </p>

                <p>
                  <a href="#fig17">Figure 17</a> shows the accuracy and loss curves for the training and validation data, along with the confusion matrix of the predictions made by the models listed in <a href="#tab-nn-summary">Table 8</a>. A lot of information to digest so let's go ahead and seeif we can gain any insights from <a href="#fig17">Figure 17</a> to improve our classifier! 
                </p>
                <ul>
                  <li>We used the model training history data from <code>model_dict</code>, the dictionary we created earlier, to plot the accuracy and loss curves.</li>
                  <li>For each curve, <span style="color: cyan; background-color: lightgray; font-size: 1.2em;">&times;</span> shows the epoch with the minimum loss. Model training stops 30 epochs after this epoch (<code>patience=30</code>).</li>
                  <li>Some of the <strong>accuracy and loss curves might be a bit misleading/inaccurate</strong> for the following reasons:
                    <p>
                      Notice that I printed out the accuracy of the optimal network (the network with the weights saved at the minimum loss epoch) for training and validation data. For each metric there are two printed values: <strong>The first number is obtained from the model history during trainig phase and the second is calculated during evaluation</strong>. We can see that the validation accuracy is the same for all of the model. However, in some of these neural networks, the model accuracy for trainig data from model history is higher than that of the evaluation, i.e., <strong>inference</strong>. To provide more details, I re-ran the model_02 calculations while saving the model at every epoch, so that I can evaluate the model in inference mode. <a href="#fig18">Figure 18</a> shows the results.
<pre class="prettyprint lang-language"><code class="language-python">checkpoint = ModelCheckpoint(filepath='model_02_all.{epoch:02d}.h5', monitor='val_loss', mode='min', verbose=1, 
                             save_best_only=False, save_weights_only=False,save_freq='epoch')
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)
callbacks_list = [checkpoint, es]
history = model.fit(vectorized_features_tr.toarray(), y_tr, epochs=100, 
                    batch_size=64, callbacks=callbacks_list, shuffle=False, 
                    validation_data=(vectorized_features_val.toarray(), y_val))
                <div style="text-align:center">
                <a id="fig18" style="font-size: 1.5em;">Figure 18</a>
                </div>
                <p class="text-align: center;">
                  <img src="NN_fig2.png" style="width: 65%; display: block; margin: 10px auto 20px;"/>
                </p>
                    <p>
                      Noteably, this is the case for the models that have <code>Dropout</code> layer in their architecture. The question is what causes this discrepancy?
                    </p>
                    <p>
                      <a href="https://keras.io/getting-started/faq/#why-is-the-training-loss-much-higher-than-the-testing-loss">Here</a> is the official <code><a href="https://keras.io">Keras</a></code> answer to this question. In short, <strong>during the training phase and depending on the dropout value, a portion of neurons are dropped, in attempt to a reduce overfitting. The accuracy and loss for training data is calculated without taking the weights of the dropped neurons into account.</strong>
                      In contrast, during the model evaluation/prediction (<em>inference</em>) all neurons remain in the network structure. The accuracy and loss for validation data, whether in training or evaluation phase, are calculated using the full network. That is why we don't see any difference in the printed values for the validation data. There are other reasons that can contribute to this behavior which is outside the scope of this project (See <a href="https://github.com/keras-team/keras/pull/9965">here</a> and <a href="http://blog.datumbox.com/the-batch-normalization-layer-of-keras-is-broken/">here</a>).
                    </p>
                  </li>
                  <li>When comparing the performance of the network on training and validation data, we notice that the inaccuracies in predicting negative reviews contributes the most to the poorer performance of the model on validation data. Looking at the confusion matrix, in any case, the model seems to be doing a great job in identifying the positive reviews. <code>Keras</code> offers the <code>class_weight</code> argument in the <code>fit()</code> method which can be used to treat the two classes differently when calculating the loss function. This is something that I explored and I'll present the outcomes later in the project.</li>
                  <li></li>
                  <li></li>
                </ul>
                <pre class="prettyprint lang-language"><code class="language-python"># load the histories
with open('model_baseline_history.pkl', 'rb') as pickle_file:
    hist_baseline = pickle.load(pickle_file)
pickle_file.close()
with open('model_00_history.pkl', 'rb') as pickle_file:
    hist_model_00 = pickle.load(pickle_file)
pickle_file.close()


                  <h4>Adding a dropout layer</h4>
                  <ul>

                    <li>vectorizers
                      <ul>
                        <li><code>CountVectorizer</code></li>
                        <li><code>TfidfVectorizer</code></li>
                        <li><code>Tokenizer</code></li>
                      </ul>
                    </li>
                    <li>NN architectures
                      <ul>
                        <li><code>ANN</code></li>
                        <li><code>CNN</code></li>
                        <li><code>Glove</code></li>
                      </ul>
                    </li>
                  </ul>
                  <p>
                    
                  </p>
                    </ul>
                  </ul>
                </p>
             </p></div></div></section>

        </div><!-- End .row -->

      </div><!-- End .container -->

    </section><!-- End Blog Section -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer" data-aos="fade-up" data-aos-easing="ease-in-out" data-aos-duration="500">

    <div class="footer-newsletter">
      <div class="container">
        <div class="row">
          <div class="col-lg-6">
            <h4>Newsletter</h4>
            <p>Subscribe here to get notified when a new material is posted</p>
          </div>
          <div class="col-lg-6">
            <form action="" method="post">
              <input type="email" name="email"><input type="submit" value="Subscribe">
            </form>
          </div>
        </div>
      </div>
    </div>

    <div class="footer-top">
      <div class="container">
        <div class="row">

          <div class="col-lg-4 col-md-6 footer-links">
            <h4>Useful Links</h4>
            <ul>
                <li><i class="bx bx-chevron-right"></i> <a href="../../index.html">Home</a></li>
                <li><i class="bx bx-chevron-right"></i> <a href="../../about.html">About Me</a></li>
                <li><i class="bx bx-chevron-right"></i> <a href="../../projects.html">Projects</a></li>
                <li><i class="bx bx-chevron-right"></i> <a href="../../tutorials.html">Tutorials</a></li>
            </ul>
          </div>
<!-- 
          <div class="col-lg-3 col-md-6 footer-links">
            <h4>Our Services</h4>
            <ul>
              <li><i class="bx bx-chevron-right"></i> <a href="#">Web Design</a></li>
              <li><i class="bx bx-chevron-right"></i> <a href="#">Web Development</a></li>
              <li><i class="bx bx-chevron-right"></i> <a href="#">Product Management</a></li>
              <li><i class="bx bx-chevron-right"></i> <a href="#">Marketing</a></li>
              <li><i class="bx bx-chevron-right"></i> <a href="#">Graphic Design</a></li>
            </ul>
          </div> -->

          <div class="col-lg-4 col-md-6 footer-contact">
            <h4>Contact</h4>
            <p>
              6455 2nd St<br>
              Alexandria, VA 22312<br>
              United States <br><br>
              <strong>Phone:</strong> +1 617 460 0555<br>
              <strong>Email:</strong> alimehdirahim@gmail.com<br>
            </p>

          </div>

          <div class="col-lg-4 col-md-6 footer-info">
            <h3>About Me</h3>
            <p>A data science enthusiast! I love developing new machine learning algorithms to address real-world problems. I try to learn something new on a daily basis.</p>
            <div class="social-links mt-3">
              <a href="https://github.com/alineu" class="Github"><i class="bx bxl-github"></i></a>
              <a href="https://www.linkedin.com/in/alimehdizadehrahimi/" class="linkedin"><i class="bx bxl-linkedin"></i></a>
              <a href="https://twitter.com/estoyali" class="twitter"><i class="bx bxl-twitter"></i></a>
              <a href="https://instagram.com/aliexplores" class="instagram"><i class="bx bxl-instagram"></i></a>
              </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container">
      <div class="copyright">
        &copy; Copyright 2021 <strong><span>Ali Mehdizadeh</span></strong>. All Rights Reserved
      </div>
      <div class="credits">
        <!-- All the links in the footer should remain intact. -->
        <!-- You can delete the links only if you purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/free-bootstrap-template-corporate-moderna/ -->
        <p>
          Page design is adopted from <a href="https://bootstrapmade.com/">BootstrapMade</a>.<br>Page icons were taken from <a href="https://www.flaticon.com">flaticon.com</a>.
        </p>
      </div>
    </div>
  </footer><!-- End Footer -->
  <a href="#" class="back-to-top"><i class="icofont-simple-up"></i></a>
                                                                <!-- Vendor JS Files -->
  <script type="text/javascript" src="../../assets/vendor/jquery/jquery.min.js"></script>
  <script type="text/javascript" src="../../assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script type="text/javascript" src="../../assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script type="text/javascript" src="../../assets/vendor/php-email-form/validate.js"></script>
  <script type="text/javascript" src="../../assets/vendor/venobox/venobox.min.js"></script>
  <script type="text/javascript" src="../../assets/vendor/waypoints/jquery.waypoints.min.js"></script>
  <script type="text/javascript" src="../../assets/vendor/counterup/counterup.min.js"></script>
  <script type="text/javascript" src="../../assets/vendor/owl.carousel/owl.carousel.min.js"></script>
  <script type="text/javascript" src="../../assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script type="text/javascript" src="../../assets/vendor/prism/prism.js"></script>
  <script type="text/javascript" src="../../assets/vendor/aos/aos.js"></script>
                                                                <!-- Template Main JS File -->
  <!-- Template Main JS File -->
    <script src="../../assets/js/main.js"></script>
    <!-- MathJax JS File -->
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
    </script>
    <script id="MathJax-script"  type="text/javascript" async src="../../assets/mathjax/tex-chtml.js"></script>
  </body>
</html>
